{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# home path\n",
    "import sys, os\n",
    "home_path = os.path.expanduser(\"~\") + '/Desktop/Molecular_kaggle'\n",
    "sys.path.append(home_path + '/py/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# module\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_profiling as pdp\n",
    "import scipy\n",
    "import pyper\n",
    "import lightgbm\n",
    "# import xgboost\n",
    "from tabulate import tabulate\n",
    "# from ggplot import *\n",
    "import warnings\n",
    "import collections\n",
    "from scipy.optimize import minimize\n",
    "from sympy import *\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set() #seabornライブラリを読み込み、スタイルをセットする\n",
    "from numpy import linalg as la\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from datetime import datetime\n",
    "\n",
    "# my module \n",
    "import importlib\n",
    "import boosting\n",
    "import base\n",
    "importlib.reload(boosting)\n",
    "importlib.reload(base)\n",
    "\n",
    "# for instance\n",
    "Process = base.Process()\n",
    "Assistance = base.Assistance()\n",
    "LightGBM = boosting.LightGBM()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4658147 observations and 49 features in train set.\n",
      "2505542 observations and 49 features in test set.\n",
      "28 observations and 1 features in features set.\n"
     ]
    }
   ],
   "source": [
    "# そのまま\n",
    "train_df, test_df, features = Process.read_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r で集約関数利用 (遅い, kernel 使う\n",
    "r = pyper.R(use_numpy='True',use_pandas='True')\n",
    "r(\"source('~/Desktop/Molecular_kaggle/script/aggregate.R, echo=FALSE)\")\n",
    "traind_df = r.get(\"train\")\n",
    "test_df = r.get(\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM\n",
    "\n",
    "- lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "param_lgb1 = Process.open_parameter(file_name = 'giba_param_lgb')\n",
    "param_lgb1\n",
    "\n",
    "# argument\n",
    "arg1 = {'train' : train_df,\n",
    "            'test' : test_df,\n",
    "            'features' : features,\n",
    "            'param' : param_lgb1,\n",
    "            'name' : 'Lightgbm base model'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~ type name: 1JHC  ~~~~~~~~~\n",
      "validation method: GroupKFold(n_splits=5) groups value: molecule_name\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l1: 1.56822\tvalid_1's l1: 1.77942\n",
      "[400]\ttraining's l1: 1.30577\tvalid_1's l1: 1.6359\n",
      "[600]\ttraining's l1: 1.13323\tvalid_1's l1: 1.55454\n",
      "[800]\ttraining's l1: 1.00921\tvalid_1's l1: 1.50397\n",
      "[1000]\ttraining's l1: 0.911789\tvalid_1's l1: 1.46951\n",
      "[1200]\ttraining's l1: 0.833073\tvalid_1's l1: 1.44524\n",
      "[1400]\ttraining's l1: 0.764371\tvalid_1's l1: 1.42612\n",
      "[1600]\ttraining's l1: 0.705651\tvalid_1's l1: 1.41139\n",
      "[1800]\ttraining's l1: 0.654397\tvalid_1's l1: 1.39884\n",
      "[2000]\ttraining's l1: 0.609349\tvalid_1's l1: 1.38839\n",
      "[2200]\ttraining's l1: 0.568639\tvalid_1's l1: 1.38011\n",
      "[2400]\ttraining's l1: 0.532449\tvalid_1's l1: 1.37298\n",
      "[2600]\ttraining's l1: 0.499286\tvalid_1's l1: 1.36718\n",
      "[2800]\ttraining's l1: 0.469259\tvalid_1's l1: 1.36149\n",
      "[3000]\ttraining's l1: 0.442252\tvalid_1's l1: 1.35716\n",
      "[3200]\ttraining's l1: 0.417429\tvalid_1's l1: 1.35352\n",
      "[3400]\ttraining's l1: 0.393707\tvalid_1's l1: 1.35032\n",
      "[3600]\ttraining's l1: 0.372503\tvalid_1's l1: 1.34724\n",
      "[3800]\ttraining's l1: 0.352674\tvalid_1's l1: 1.34443\n",
      "[4000]\ttraining's l1: 0.334259\tvalid_1's l1: 1.34219\n",
      "[4200]\ttraining's l1: 0.316904\tvalid_1's l1: 1.33998\n",
      "[4400]\ttraining's l1: 0.30074\tvalid_1's l1: 1.33813\n",
      "[4600]\ttraining's l1: 0.28582\tvalid_1's l1: 1.33669\n",
      "[4800]\ttraining's l1: 0.271811\tvalid_1's l1: 1.33547\n",
      "[5000]\ttraining's l1: 0.258617\tvalid_1's l1: 1.33433\n",
      "[5200]\ttraining's l1: 0.24618\tvalid_1's l1: 1.33344\n",
      "[5400]\ttraining's l1: 0.234627\tvalid_1's l1: 1.33241\n",
      "[5600]\ttraining's l1: 0.223755\tvalid_1's l1: 1.33174\n",
      "[5800]\ttraining's l1: 0.213321\tvalid_1's l1: 1.33102\n",
      "[6000]\ttraining's l1: 0.203791\tvalid_1's l1: 1.33028\n",
      "[6200]\ttraining's l1: 0.194592\tvalid_1's l1: 1.32971\n",
      "[6400]\ttraining's l1: 0.186114\tvalid_1's l1: 1.32909\n",
      "[6600]\ttraining's l1: 0.178052\tvalid_1's l1: 1.3283\n",
      "[6800]\ttraining's l1: 0.170357\tvalid_1's l1: 1.32778\n",
      "[7000]\ttraining's l1: 0.162948\tvalid_1's l1: 1.3273\n",
      "[7200]\ttraining's l1: 0.156048\tvalid_1's l1: 1.32693\n",
      "[7400]\ttraining's l1: 0.149488\tvalid_1's l1: 1.32661\n",
      "[7600]\ttraining's l1: 0.143244\tvalid_1's l1: 1.32633\n",
      "[7800]\ttraining's l1: 0.137254\tvalid_1's l1: 1.32605\n",
      "[8000]\ttraining's l1: 0.131606\tvalid_1's l1: 1.32563\n",
      "[8200]\ttraining's l1: 0.12629\tvalid_1's l1: 1.3254\n",
      "[8400]\ttraining's l1: 0.121051\tvalid_1's l1: 1.32523\n",
      "[8600]\ttraining's l1: 0.116269\tvalid_1's l1: 1.32496\n",
      "[8800]\ttraining's l1: 0.11162\tvalid_1's l1: 1.32471\n",
      "[9000]\ttraining's l1: 0.107165\tvalid_1's l1: 1.32445\n",
      "[9200]\ttraining's l1: 0.102949\tvalid_1's l1: 1.32425\n",
      "[9400]\ttraining's l1: 0.0990367\tvalid_1's l1: 1.32413\n",
      "[9600]\ttraining's l1: 0.0952497\tvalid_1's l1: 1.32398\n",
      "[9800]\ttraining's l1: 0.0915962\tvalid_1's l1: 1.32381\n",
      "[10000]\ttraining's l1: 0.0881457\tvalid_1's l1: 1.32366\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.0881457\tvalid_1's l1: 1.32366\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l1: 1.56682\tvalid_1's l1: 1.774\n",
      "[400]\ttraining's l1: 1.29874\tvalid_1's l1: 1.62536\n",
      "[600]\ttraining's l1: 1.13037\tvalid_1's l1: 1.5477\n",
      "[800]\ttraining's l1: 1.00851\tvalid_1's l1: 1.49764\n",
      "[1000]\ttraining's l1: 0.911304\tvalid_1's l1: 1.46404\n",
      "[1200]\ttraining's l1: 0.830045\tvalid_1's l1: 1.43784\n",
      "[1400]\ttraining's l1: 0.763107\tvalid_1's l1: 1.41939\n",
      "[1600]\ttraining's l1: 0.706111\tvalid_1's l1: 1.40459\n",
      "[1800]\ttraining's l1: 0.655112\tvalid_1's l1: 1.39172\n",
      "[2000]\ttraining's l1: 0.609018\tvalid_1's l1: 1.38033\n",
      "[2200]\ttraining's l1: 0.568158\tvalid_1's l1: 1.37114\n",
      "[2400]\ttraining's l1: 0.53245\tvalid_1's l1: 1.36442\n",
      "[2600]\ttraining's l1: 0.49969\tvalid_1's l1: 1.35878\n",
      "[2800]\ttraining's l1: 0.469265\tvalid_1's l1: 1.35319\n",
      "[3000]\ttraining's l1: 0.442142\tvalid_1's l1: 1.34875\n",
      "[3200]\ttraining's l1: 0.41684\tvalid_1's l1: 1.34455\n",
      "[3400]\ttraining's l1: 0.393465\tvalid_1's l1: 1.34119\n",
      "[3600]\ttraining's l1: 0.372327\tvalid_1's l1: 1.33787\n",
      "[3800]\ttraining's l1: 0.35265\tvalid_1's l1: 1.33538\n",
      "[4000]\ttraining's l1: 0.334192\tvalid_1's l1: 1.33303\n",
      "[4200]\ttraining's l1: 0.317086\tvalid_1's l1: 1.33081\n",
      "[4400]\ttraining's l1: 0.300968\tvalid_1's l1: 1.32916\n",
      "[4600]\ttraining's l1: 0.285807\tvalid_1's l1: 1.32763\n",
      "[4800]\ttraining's l1: 0.271808\tvalid_1's l1: 1.3263\n",
      "[5000]\ttraining's l1: 0.25858\tvalid_1's l1: 1.32504\n",
      "[5200]\ttraining's l1: 0.24656\tvalid_1's l1: 1.32392\n",
      "[5400]\ttraining's l1: 0.234885\tvalid_1's l1: 1.32273\n",
      "[5600]\ttraining's l1: 0.22411\tvalid_1's l1: 1.32186\n",
      "[5800]\ttraining's l1: 0.213847\tvalid_1's l1: 1.32105\n",
      "[6000]\ttraining's l1: 0.204098\tvalid_1's l1: 1.32018\n",
      "[6200]\ttraining's l1: 0.194849\tvalid_1's l1: 1.31934\n",
      "[6400]\ttraining's l1: 0.186333\tvalid_1's l1: 1.31873\n",
      "[6600]\ttraining's l1: 0.178304\tvalid_1's l1: 1.3182\n",
      "[6800]\ttraining's l1: 0.170564\tvalid_1's l1: 1.3177\n",
      "[7000]\ttraining's l1: 0.163106\tvalid_1's l1: 1.3173\n",
      "[7200]\ttraining's l1: 0.156128\tvalid_1's l1: 1.3168\n",
      "[7400]\ttraining's l1: 0.149541\tvalid_1's l1: 1.31635\n",
      "[7600]\ttraining's l1: 0.143269\tvalid_1's l1: 1.31597\n",
      "[7800]\ttraining's l1: 0.137274\tvalid_1's l1: 1.31554\n",
      "[8000]\ttraining's l1: 0.131576\tvalid_1's l1: 1.3152\n",
      "[8200]\ttraining's l1: 0.126281\tvalid_1's l1: 1.31496\n",
      "[8400]\ttraining's l1: 0.121185\tvalid_1's l1: 1.31471\n",
      "[8600]\ttraining's l1: 0.116218\tvalid_1's l1: 1.31442\n",
      "[8800]\ttraining's l1: 0.111645\tvalid_1's l1: 1.31422\n",
      "[9000]\ttraining's l1: 0.107331\tvalid_1's l1: 1.31412\n",
      "[9200]\ttraining's l1: 0.103128\tvalid_1's l1: 1.3139\n",
      "[9400]\ttraining's l1: 0.0991359\tvalid_1's l1: 1.31373\n",
      "[9600]\ttraining's l1: 0.0953546\tvalid_1's l1: 1.31356\n",
      "[9800]\ttraining's l1: 0.0917244\tvalid_1's l1: 1.31339\n",
      "[10000]\ttraining's l1: 0.0883073\tvalid_1's l1: 1.31326\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.0883073\tvalid_1's l1: 1.31326\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l1: 1.57565\tvalid_1's l1: 1.77358\n",
      "[400]\ttraining's l1: 1.30458\tvalid_1's l1: 1.62557\n",
      "[600]\ttraining's l1: 1.13326\tvalid_1's l1: 1.54564\n",
      "[800]\ttraining's l1: 1.00978\tvalid_1's l1: 1.49507\n",
      "[1000]\ttraining's l1: 0.912707\tvalid_1's l1: 1.46026\n",
      "[1200]\ttraining's l1: 0.83198\tvalid_1's l1: 1.43534\n",
      "[1400]\ttraining's l1: 0.764584\tvalid_1's l1: 1.41608\n",
      "[1600]\ttraining's l1: 0.706236\tvalid_1's l1: 1.40064\n",
      "[1800]\ttraining's l1: 0.655374\tvalid_1's l1: 1.38879\n",
      "[2000]\ttraining's l1: 0.610187\tvalid_1's l1: 1.37794\n",
      "[2200]\ttraining's l1: 0.569371\tvalid_1's l1: 1.36929\n",
      "[2400]\ttraining's l1: 0.532691\tvalid_1's l1: 1.36189\n",
      "[2600]\ttraining's l1: 0.499864\tvalid_1's l1: 1.35599\n",
      "[2800]\ttraining's l1: 0.469935\tvalid_1's l1: 1.35036\n",
      "[3000]\ttraining's l1: 0.44288\tvalid_1's l1: 1.34569\n",
      "[3200]\ttraining's l1: 0.417562\tvalid_1's l1: 1.34196\n",
      "[3400]\ttraining's l1: 0.39437\tvalid_1's l1: 1.33874\n",
      "[3600]\ttraining's l1: 0.373085\tvalid_1's l1: 1.3355\n",
      "[3800]\ttraining's l1: 0.353407\tvalid_1's l1: 1.33294\n",
      "[4000]\ttraining's l1: 0.334693\tvalid_1's l1: 1.3305\n",
      "[4200]\ttraining's l1: 0.31763\tvalid_1's l1: 1.32882\n",
      "[4400]\ttraining's l1: 0.30158\tvalid_1's l1: 1.32693\n",
      "[4600]\ttraining's l1: 0.286561\tvalid_1's l1: 1.32508\n",
      "[4800]\ttraining's l1: 0.272607\tvalid_1's l1: 1.32372\n",
      "[5000]\ttraining's l1: 0.259376\tvalid_1's l1: 1.32229\n",
      "[5200]\ttraining's l1: 0.247116\tvalid_1's l1: 1.32115\n",
      "[5400]\ttraining's l1: 0.235557\tvalid_1's l1: 1.32004\n",
      "[5600]\ttraining's l1: 0.224588\tvalid_1's l1: 1.31907\n",
      "[5800]\ttraining's l1: 0.214137\tvalid_1's l1: 1.31805\n",
      "[6000]\ttraining's l1: 0.20448\tvalid_1's l1: 1.31724\n",
      "[6200]\ttraining's l1: 0.195408\tvalid_1's l1: 1.3165\n",
      "[6400]\ttraining's l1: 0.18673\tvalid_1's l1: 1.31571\n",
      "[6600]\ttraining's l1: 0.178481\tvalid_1's l1: 1.31495\n",
      "[6800]\ttraining's l1: 0.170675\tvalid_1's l1: 1.31445\n",
      "[7000]\ttraining's l1: 0.163335\tvalid_1's l1: 1.31397\n",
      "[7200]\ttraining's l1: 0.156424\tvalid_1's l1: 1.31353\n",
      "[7400]\ttraining's l1: 0.149855\tvalid_1's l1: 1.31307\n",
      "[7600]\ttraining's l1: 0.143555\tvalid_1's l1: 1.31274\n",
      "[7800]\ttraining's l1: 0.13768\tvalid_1's l1: 1.3124\n",
      "[8000]\ttraining's l1: 0.132137\tvalid_1's l1: 1.31211\n",
      "[8200]\ttraining's l1: 0.126685\tvalid_1's l1: 1.31177\n",
      "[8400]\ttraining's l1: 0.121566\tvalid_1's l1: 1.31149\n",
      "[8600]\ttraining's l1: 0.116609\tvalid_1's l1: 1.31117\n",
      "[8800]\ttraining's l1: 0.112058\tvalid_1's l1: 1.31094\n",
      "[9000]\ttraining's l1: 0.107609\tvalid_1's l1: 1.31071\n",
      "[9200]\ttraining's l1: 0.103451\tvalid_1's l1: 1.31055\n",
      "[9400]\ttraining's l1: 0.0994643\tvalid_1's l1: 1.31035\n",
      "[9600]\ttraining's l1: 0.0956626\tvalid_1's l1: 1.3102\n",
      "[9800]\ttraining's l1: 0.0919966\tvalid_1's l1: 1.31008\n",
      "[10000]\ttraining's l1: 0.0884657\tvalid_1's l1: 1.30993\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.0884657\tvalid_1's l1: 1.30993\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l1: 1.57745\tvalid_1's l1: 1.76879\n",
      "[400]\ttraining's l1: 1.30573\tvalid_1's l1: 1.61649\n",
      "[600]\ttraining's l1: 1.13258\tvalid_1's l1: 1.53657\n",
      "[800]\ttraining's l1: 1.00937\tvalid_1's l1: 1.48709\n",
      "[1000]\ttraining's l1: 0.913158\tvalid_1's l1: 1.45384\n",
      "[1200]\ttraining's l1: 0.832962\tvalid_1's l1: 1.42864\n",
      "[1400]\ttraining's l1: 0.765126\tvalid_1's l1: 1.40873\n",
      "[1600]\ttraining's l1: 0.707612\tvalid_1's l1: 1.39436\n",
      "[1800]\ttraining's l1: 0.655327\tvalid_1's l1: 1.3816\n",
      "[2000]\ttraining's l1: 0.610309\tvalid_1's l1: 1.37039\n",
      "[2200]\ttraining's l1: 0.569556\tvalid_1's l1: 1.36186\n",
      "[2400]\ttraining's l1: 0.53303\tvalid_1's l1: 1.35471\n",
      "[2600]\ttraining's l1: 0.500414\tvalid_1's l1: 1.34916\n",
      "[2800]\ttraining's l1: 0.471015\tvalid_1's l1: 1.34408\n",
      "[3000]\ttraining's l1: 0.443864\tvalid_1's l1: 1.33963\n",
      "[3200]\ttraining's l1: 0.419153\tvalid_1's l1: 1.33633\n",
      "[3400]\ttraining's l1: 0.395812\tvalid_1's l1: 1.33309\n",
      "[3600]\ttraining's l1: 0.374077\tvalid_1's l1: 1.32984\n",
      "[3800]\ttraining's l1: 0.353773\tvalid_1's l1: 1.32714\n",
      "[4000]\ttraining's l1: 0.335058\tvalid_1's l1: 1.32463\n",
      "[4200]\ttraining's l1: 0.317721\tvalid_1's l1: 1.32234\n",
      "[4400]\ttraining's l1: 0.301839\tvalid_1's l1: 1.32057\n",
      "[4600]\ttraining's l1: 0.286948\tvalid_1's l1: 1.31916\n",
      "[4800]\ttraining's l1: 0.272911\tvalid_1's l1: 1.31776\n",
      "[5000]\ttraining's l1: 0.259777\tvalid_1's l1: 1.31642\n",
      "[5200]\ttraining's l1: 0.247526\tvalid_1's l1: 1.31531\n",
      "[5400]\ttraining's l1: 0.235829\tvalid_1's l1: 1.31438\n",
      "[5600]\ttraining's l1: 0.224766\tvalid_1's l1: 1.3135\n",
      "[5800]\ttraining's l1: 0.21467\tvalid_1's l1: 1.31266\n",
      "[6000]\ttraining's l1: 0.204769\tvalid_1's l1: 1.31183\n",
      "[6200]\ttraining's l1: 0.195744\tvalid_1's l1: 1.31113\n",
      "[6400]\ttraining's l1: 0.187217\tvalid_1's l1: 1.31049\n",
      "[6600]\ttraining's l1: 0.179149\tvalid_1's l1: 1.30986\n",
      "[6800]\ttraining's l1: 0.171332\tvalid_1's l1: 1.3094\n",
      "[7000]\ttraining's l1: 0.163876\tvalid_1's l1: 1.30895\n",
      "[7200]\ttraining's l1: 0.156819\tvalid_1's l1: 1.30847\n",
      "[7400]\ttraining's l1: 0.150233\tvalid_1's l1: 1.30813\n",
      "[7600]\ttraining's l1: 0.143819\tvalid_1's l1: 1.30783\n",
      "[7800]\ttraining's l1: 0.137835\tvalid_1's l1: 1.30752\n",
      "[8000]\ttraining's l1: 0.132223\tvalid_1's l1: 1.30728\n",
      "[8200]\ttraining's l1: 0.126731\tvalid_1's l1: 1.30701\n",
      "[8400]\ttraining's l1: 0.121576\tvalid_1's l1: 1.3067\n",
      "[8600]\ttraining's l1: 0.116724\tvalid_1's l1: 1.3064\n",
      "[8800]\ttraining's l1: 0.112132\tvalid_1's l1: 1.30609\n",
      "[9000]\ttraining's l1: 0.107695\tvalid_1's l1: 1.30584\n",
      "[9200]\ttraining's l1: 0.103423\tvalid_1's l1: 1.3056\n",
      "[9400]\ttraining's l1: 0.099502\tvalid_1's l1: 1.30544\n",
      "[9600]\ttraining's l1: 0.0956399\tvalid_1's l1: 1.30532\n",
      "[9800]\ttraining's l1: 0.0919146\tvalid_1's l1: 1.30513\n",
      "[10000]\ttraining's l1: 0.088498\tvalid_1's l1: 1.30501\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.088498\tvalid_1's l1: 1.30501\n",
      "fold n°5\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l1: 1.56892\tvalid_1's l1: 1.77244\n",
      "[400]\ttraining's l1: 1.30116\tvalid_1's l1: 1.62486\n",
      "[600]\ttraining's l1: 1.13242\tvalid_1's l1: 1.54735\n",
      "[800]\ttraining's l1: 1.01022\tvalid_1's l1: 1.49811\n",
      "[1000]\ttraining's l1: 0.911765\tvalid_1's l1: 1.46356\n",
      "[1200]\ttraining's l1: 0.833434\tvalid_1's l1: 1.43902\n",
      "[1400]\ttraining's l1: 0.765322\tvalid_1's l1: 1.41984\n",
      "[1600]\ttraining's l1: 0.706883\tvalid_1's l1: 1.4043\n",
      "[1800]\ttraining's l1: 0.655325\tvalid_1's l1: 1.39203\n",
      "[2000]\ttraining's l1: 0.609805\tvalid_1's l1: 1.38167\n",
      "[2200]\ttraining's l1: 0.570083\tvalid_1's l1: 1.37246\n",
      "[2400]\ttraining's l1: 0.533632\tvalid_1's l1: 1.36557\n",
      "[2600]\ttraining's l1: 0.501186\tvalid_1's l1: 1.36008\n",
      "[2800]\ttraining's l1: 0.470578\tvalid_1's l1: 1.35386\n",
      "[3000]\ttraining's l1: 0.443383\tvalid_1's l1: 1.34949\n",
      "[3200]\ttraining's l1: 0.418181\tvalid_1's l1: 1.34556\n",
      "[3400]\ttraining's l1: 0.394747\tvalid_1's l1: 1.34211\n",
      "[3600]\ttraining's l1: 0.373346\tvalid_1's l1: 1.33867\n",
      "[3800]\ttraining's l1: 0.353518\tvalid_1's l1: 1.3359\n",
      "[4000]\ttraining's l1: 0.33492\tvalid_1's l1: 1.33353\n",
      "[4200]\ttraining's l1: 0.317843\tvalid_1's l1: 1.3317\n",
      "[4400]\ttraining's l1: 0.301676\tvalid_1's l1: 1.32979\n",
      "[4600]\ttraining's l1: 0.286619\tvalid_1's l1: 1.32808\n",
      "[4800]\ttraining's l1: 0.272414\tvalid_1's l1: 1.32664\n",
      "[5000]\ttraining's l1: 0.259252\tvalid_1's l1: 1.32522\n",
      "[5200]\ttraining's l1: 0.247074\tvalid_1's l1: 1.3241\n",
      "[5400]\ttraining's l1: 0.235473\tvalid_1's l1: 1.32304\n",
      "[5600]\ttraining's l1: 0.22444\tvalid_1's l1: 1.32213\n",
      "[5800]\ttraining's l1: 0.214177\tvalid_1's l1: 1.32122\n",
      "[6000]\ttraining's l1: 0.204495\tvalid_1's l1: 1.32035\n",
      "[6200]\ttraining's l1: 0.195318\tvalid_1's l1: 1.31963\n",
      "[6400]\ttraining's l1: 0.18667\tvalid_1's l1: 1.31907\n",
      "[6600]\ttraining's l1: 0.178654\tvalid_1's l1: 1.31848\n",
      "[6800]\ttraining's l1: 0.170903\tvalid_1's l1: 1.3179\n",
      "[7000]\ttraining's l1: 0.163441\tvalid_1's l1: 1.31743\n",
      "[7200]\ttraining's l1: 0.156483\tvalid_1's l1: 1.31703\n",
      "[7400]\ttraining's l1: 0.149935\tvalid_1's l1: 1.31668\n",
      "[7600]\ttraining's l1: 0.14376\tvalid_1's l1: 1.31638\n",
      "[7800]\ttraining's l1: 0.137841\tvalid_1's l1: 1.31606\n",
      "[8000]\ttraining's l1: 0.132252\tvalid_1's l1: 1.31579\n",
      "[8200]\ttraining's l1: 0.126774\tvalid_1's l1: 1.3156\n",
      "[8400]\ttraining's l1: 0.121692\tvalid_1's l1: 1.31535\n",
      "[8600]\ttraining's l1: 0.116837\tvalid_1's l1: 1.31506\n",
      "[8800]\ttraining's l1: 0.112165\tvalid_1's l1: 1.31488\n",
      "[9000]\ttraining's l1: 0.10775\tvalid_1's l1: 1.31464\n",
      "[9200]\ttraining's l1: 0.103496\tvalid_1's l1: 1.31447\n",
      "[9400]\ttraining's l1: 0.0994243\tvalid_1's l1: 1.31429\n",
      "[9600]\ttraining's l1: 0.0955905\tvalid_1's l1: 1.31405\n",
      "[9800]\ttraining's l1: 0.0918976\tvalid_1's l1: 1.31393\n",
      "[10000]\ttraining's l1: 0.0884409\tvalid_1's l1: 1.31381\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.0884409\tvalid_1's l1: 1.31381\n",
      "~~~~~~~~~ type name: 2JHH  ~~~~~~~~~\n",
      "validation method: GroupKFold(n_splits=5) groups value: molecule_name\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l1: 0.304251\tvalid_1's l1: 0.365197\n",
      "[400]\ttraining's l1: 0.245661\tvalid_1's l1: 0.340011\n",
      "[600]\ttraining's l1: 0.207651\tvalid_1's l1: 0.328656\n",
      "[800]\ttraining's l1: 0.180559\tvalid_1's l1: 0.32211\n",
      "[1000]\ttraining's l1: 0.159477\tvalid_1's l1: 0.317753\n",
      "[1200]\ttraining's l1: 0.142641\tvalid_1's l1: 0.314848\n",
      "[1400]\ttraining's l1: 0.128229\tvalid_1's l1: 0.312777\n",
      "[1600]\ttraining's l1: 0.115664\tvalid_1's l1: 0.311424\n",
      "[1800]\ttraining's l1: 0.104895\tvalid_1's l1: 0.310159\n",
      "[2000]\ttraining's l1: 0.0956757\tvalid_1's l1: 0.309279\n",
      "[2200]\ttraining's l1: 0.0874327\tvalid_1's l1: 0.308537\n",
      "[2400]\ttraining's l1: 0.0800731\tvalid_1's l1: 0.307857\n",
      "[2600]\ttraining's l1: 0.0734868\tvalid_1's l1: 0.307427\n",
      "[2800]\ttraining's l1: 0.0675736\tvalid_1's l1: 0.307117\n",
      "[3000]\ttraining's l1: 0.0623603\tvalid_1's l1: 0.306829\n",
      "[3200]\ttraining's l1: 0.0576149\tvalid_1's l1: 0.306609\n",
      "[3400]\ttraining's l1: 0.0532283\tvalid_1's l1: 0.30645\n",
      "[3600]\ttraining's l1: 0.0492763\tvalid_1's l1: 0.306284\n",
      "[3800]\ttraining's l1: 0.0457394\tvalid_1's l1: 0.306167\n",
      "[4000]\ttraining's l1: 0.0424553\tvalid_1's l1: 0.30606\n",
      "[4200]\ttraining's l1: 0.0394643\tvalid_1's l1: 0.305985\n",
      "[4400]\ttraining's l1: 0.0367415\tvalid_1's l1: 0.305876\n",
      "[4600]\ttraining's l1: 0.0341761\tvalid_1's l1: 0.305802\n",
      "[4800]\ttraining's l1: 0.0318876\tvalid_1's l1: 0.305755\n",
      "[5000]\ttraining's l1: 0.0297571\tvalid_1's l1: 0.305695\n",
      "[5200]\ttraining's l1: 0.0277771\tvalid_1's l1: 0.30567\n",
      "[5400]\ttraining's l1: 0.0259828\tvalid_1's l1: 0.305609\n",
      "[5600]\ttraining's l1: 0.024275\tvalid_1's l1: 0.305575\n",
      "[5800]\ttraining's l1: 0.0227109\tvalid_1's l1: 0.305575\n",
      "Early stopping, best iteration is:\n",
      "[5646]\ttraining's l1: 0.0239085\tvalid_1's l1: 0.305561\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l1: 0.305731\tvalid_1's l1: 0.368765\n",
      "[400]\ttraining's l1: 0.245114\tvalid_1's l1: 0.343018\n",
      "[600]\ttraining's l1: 0.208104\tvalid_1's l1: 0.332079\n",
      "[800]\ttraining's l1: 0.181205\tvalid_1's l1: 0.325257\n",
      "[1000]\ttraining's l1: 0.159937\tvalid_1's l1: 0.321132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1200]\ttraining's l1: 0.14272\tvalid_1's l1: 0.318116\n",
      "[1400]\ttraining's l1: 0.128207\tvalid_1's l1: 0.316113\n",
      "[1600]\ttraining's l1: 0.115992\tvalid_1's l1: 0.314536\n",
      "[1800]\ttraining's l1: 0.105121\tvalid_1's l1: 0.313353\n",
      "[2000]\ttraining's l1: 0.0956796\tvalid_1's l1: 0.312224\n",
      "[2200]\ttraining's l1: 0.0874266\tvalid_1's l1: 0.311575\n",
      "[2400]\ttraining's l1: 0.0800146\tvalid_1's l1: 0.311084\n",
      "[2600]\ttraining's l1: 0.0734155\tvalid_1's l1: 0.31064\n",
      "[2800]\ttraining's l1: 0.0675791\tvalid_1's l1: 0.310347\n",
      "[3000]\ttraining's l1: 0.0623276\tvalid_1's l1: 0.309985\n",
      "[3200]\ttraining's l1: 0.0575174\tvalid_1's l1: 0.309819\n",
      "[3400]\ttraining's l1: 0.0531769\tvalid_1's l1: 0.309606\n",
      "[3600]\ttraining's l1: 0.0492636\tvalid_1's l1: 0.309485\n",
      "[3800]\ttraining's l1: 0.0456429\tvalid_1's l1: 0.309352\n",
      "[4000]\ttraining's l1: 0.0424144\tvalid_1's l1: 0.309258\n",
      "[4200]\ttraining's l1: 0.0394677\tvalid_1's l1: 0.309185\n",
      "[4400]\ttraining's l1: 0.0366396\tvalid_1's l1: 0.309134\n",
      "[4600]\ttraining's l1: 0.0341418\tvalid_1's l1: 0.309066\n",
      "[4800]\ttraining's l1: 0.0317695\tvalid_1's l1: 0.309043\n",
      "[5000]\ttraining's l1: 0.0296335\tvalid_1's l1: 0.308994\n",
      "[5200]\ttraining's l1: 0.027675\tvalid_1's l1: 0.308969\n",
      "[5400]\ttraining's l1: 0.0258875\tvalid_1's l1: 0.308943\n",
      "[5600]\ttraining's l1: 0.0242104\tvalid_1's l1: 0.308929\n",
      "[5800]\ttraining's l1: 0.0226562\tvalid_1's l1: 0.308875\n",
      "[6000]\ttraining's l1: 0.0212086\tvalid_1's l1: 0.308829\n",
      "[6200]\ttraining's l1: 0.0198476\tvalid_1's l1: 0.30881\n",
      "[6400]\ttraining's l1: 0.0185882\tvalid_1's l1: 0.308806\n",
      "[6600]\ttraining's l1: 0.0174582\tvalid_1's l1: 0.308791\n",
      "[6800]\ttraining's l1: 0.0163788\tvalid_1's l1: 0.308774\n",
      "[7000]\ttraining's l1: 0.0153754\tvalid_1's l1: 0.308758\n",
      "[7200]\ttraining's l1: 0.0144534\tvalid_1's l1: 0.30875\n",
      "[7400]\ttraining's l1: 0.013575\tvalid_1's l1: 0.308723\n",
      "[7600]\ttraining's l1: 0.0127805\tvalid_1's l1: 0.308712\n",
      "[7800]\ttraining's l1: 0.0120175\tvalid_1's l1: 0.308702\n",
      "[8000]\ttraining's l1: 0.0113067\tvalid_1's l1: 0.3087\n",
      "[8200]\ttraining's l1: 0.0106425\tvalid_1's l1: 0.308691\n",
      "[8400]\ttraining's l1: 0.010038\tvalid_1's l1: 0.308686\n",
      "Early stopping, best iteration is:\n",
      "[8261]\ttraining's l1: 0.0104496\tvalid_1's l1: 0.308685\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l1: 0.305249\tvalid_1's l1: 0.36974\n",
      "[400]\ttraining's l1: 0.244643\tvalid_1's l1: 0.343129\n",
      "[600]\ttraining's l1: 0.207368\tvalid_1's l1: 0.331435\n",
      "[800]\ttraining's l1: 0.180528\tvalid_1's l1: 0.324704\n",
      "[1000]\ttraining's l1: 0.159685\tvalid_1's l1: 0.32032\n",
      "[1200]\ttraining's l1: 0.142537\tvalid_1's l1: 0.317335\n",
      "[1400]\ttraining's l1: 0.127858\tvalid_1's l1: 0.315088\n",
      "[1600]\ttraining's l1: 0.115549\tvalid_1's l1: 0.313262\n",
      "[1800]\ttraining's l1: 0.104871\tvalid_1's l1: 0.312083\n",
      "[2000]\ttraining's l1: 0.0954644\tvalid_1's l1: 0.311097\n",
      "[2200]\ttraining's l1: 0.0873013\tvalid_1's l1: 0.310309\n",
      "[2400]\ttraining's l1: 0.0800035\tvalid_1's l1: 0.309838\n",
      "[2600]\ttraining's l1: 0.0734547\tvalid_1's l1: 0.309363\n",
      "[2800]\ttraining's l1: 0.0675353\tvalid_1's l1: 0.308915\n",
      "[3000]\ttraining's l1: 0.0622633\tvalid_1's l1: 0.308586\n",
      "[3200]\ttraining's l1: 0.0575281\tvalid_1's l1: 0.308388\n",
      "[3400]\ttraining's l1: 0.0531852\tvalid_1's l1: 0.30821\n",
      "[3600]\ttraining's l1: 0.0492629\tvalid_1's l1: 0.30795\n",
      "[3800]\ttraining's l1: 0.0456896\tvalid_1's l1: 0.307794\n",
      "[4000]\ttraining's l1: 0.0424142\tvalid_1's l1: 0.307654\n",
      "[4200]\ttraining's l1: 0.0394555\tvalid_1's l1: 0.307567\n",
      "[4400]\ttraining's l1: 0.0367026\tvalid_1's l1: 0.307526\n",
      "[4600]\ttraining's l1: 0.0342029\tvalid_1's l1: 0.307408\n",
      "[4800]\ttraining's l1: 0.0318852\tvalid_1's l1: 0.307327\n",
      "[5000]\ttraining's l1: 0.0297554\tvalid_1's l1: 0.307275\n",
      "[5200]\ttraining's l1: 0.0278005\tvalid_1's l1: 0.307225\n",
      "[5400]\ttraining's l1: 0.0259668\tvalid_1's l1: 0.307197\n",
      "[5600]\ttraining's l1: 0.0243028\tvalid_1's l1: 0.307178\n",
      "[5800]\ttraining's l1: 0.0227228\tvalid_1's l1: 0.307136\n",
      "[6000]\ttraining's l1: 0.0212545\tvalid_1's l1: 0.307118\n",
      "[6200]\ttraining's l1: 0.0199154\tvalid_1's l1: 0.307102\n",
      "[6400]\ttraining's l1: 0.0186919\tvalid_1's l1: 0.307074\n",
      "[6600]\ttraining's l1: 0.0175446\tvalid_1's l1: 0.307047\n",
      "[6800]\ttraining's l1: 0.0164575\tvalid_1's l1: 0.307042\n",
      "[7000]\ttraining's l1: 0.0154289\tvalid_1's l1: 0.307026\n",
      "[7200]\ttraining's l1: 0.014504\tvalid_1's l1: 0.307022\n",
      "Early stopping, best iteration is:\n",
      "[7090]\ttraining's l1: 0.0149963\tvalid_1's l1: 0.307012\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l1: 0.306511\tvalid_1's l1: 0.369116\n",
      "[400]\ttraining's l1: 0.24605\tvalid_1's l1: 0.34309\n",
      "[600]\ttraining's l1: 0.208327\tvalid_1's l1: 0.332074\n",
      "[800]\ttraining's l1: 0.181442\tvalid_1's l1: 0.325408\n",
      "[1000]\ttraining's l1: 0.160129\tvalid_1's l1: 0.321012\n",
      "[1200]\ttraining's l1: 0.142564\tvalid_1's l1: 0.317352\n",
      "[1400]\ttraining's l1: 0.128094\tvalid_1's l1: 0.314976\n",
      "[1600]\ttraining's l1: 0.115741\tvalid_1's l1: 0.313447\n",
      "[1800]\ttraining's l1: 0.104926\tvalid_1's l1: 0.312194\n",
      "[2000]\ttraining's l1: 0.0955587\tvalid_1's l1: 0.311319\n",
      "[2200]\ttraining's l1: 0.0873953\tvalid_1's l1: 0.310589\n",
      "[2400]\ttraining's l1: 0.0799574\tvalid_1's l1: 0.309999\n",
      "[2600]\ttraining's l1: 0.0734747\tvalid_1's l1: 0.309547\n",
      "[2800]\ttraining's l1: 0.0676394\tvalid_1's l1: 0.309097\n",
      "[3000]\ttraining's l1: 0.0623225\tvalid_1's l1: 0.30881\n",
      "[3200]\ttraining's l1: 0.057576\tvalid_1's l1: 0.308619\n",
      "[3400]\ttraining's l1: 0.0532196\tvalid_1's l1: 0.308448\n",
      "[3600]\ttraining's l1: 0.0493371\tvalid_1's l1: 0.308242\n",
      "[3800]\ttraining's l1: 0.0457089\tvalid_1's l1: 0.308109\n",
      "[4000]\ttraining's l1: 0.0424504\tvalid_1's l1: 0.308013\n",
      "[4200]\ttraining's l1: 0.0394628\tvalid_1's l1: 0.307922\n",
      "[4400]\ttraining's l1: 0.0367186\tvalid_1's l1: 0.307896\n",
      "Early stopping, best iteration is:\n",
      "[4276]\ttraining's l1: 0.0383956\tvalid_1's l1: 0.307884\n",
      "fold n°5\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l1: 0.304254\tvalid_1's l1: 0.368832\n",
      "[400]\ttraining's l1: 0.244126\tvalid_1's l1: 0.342822\n",
      "[600]\ttraining's l1: 0.207079\tvalid_1's l1: 0.331253\n",
      "[800]\ttraining's l1: 0.180397\tvalid_1's l1: 0.324474\n",
      "[1000]\ttraining's l1: 0.159757\tvalid_1's l1: 0.320224\n",
      "[1200]\ttraining's l1: 0.142359\tvalid_1's l1: 0.31737\n",
      "[1400]\ttraining's l1: 0.127827\tvalid_1's l1: 0.315144\n",
      "[1600]\ttraining's l1: 0.115383\tvalid_1's l1: 0.313718\n",
      "[1800]\ttraining's l1: 0.104726\tvalid_1's l1: 0.312612\n",
      "[2000]\ttraining's l1: 0.0955023\tvalid_1's l1: 0.311753\n",
      "[2200]\ttraining's l1: 0.0872366\tvalid_1's l1: 0.311089\n",
      "[2400]\ttraining's l1: 0.0798259\tvalid_1's l1: 0.310628\n",
      "[2600]\ttraining's l1: 0.0732852\tvalid_1's l1: 0.310336\n",
      "[2800]\ttraining's l1: 0.0674296\tvalid_1's l1: 0.309927\n",
      "[3000]\ttraining's l1: 0.0621774\tvalid_1's l1: 0.309728\n",
      "[3200]\ttraining's l1: 0.0574372\tvalid_1's l1: 0.309424\n",
      "[3400]\ttraining's l1: 0.0531315\tvalid_1's l1: 0.309329\n",
      "[3600]\ttraining's l1: 0.0491962\tvalid_1's l1: 0.309212\n",
      "[3800]\ttraining's l1: 0.0455434\tvalid_1's l1: 0.309067\n",
      "[4000]\ttraining's l1: 0.0422871\tvalid_1's l1: 0.308921\n",
      "[4200]\ttraining's l1: 0.0392789\tvalid_1's l1: 0.308857\n",
      "[4400]\ttraining's l1: 0.0365425\tvalid_1's l1: 0.30875\n",
      "[4600]\ttraining's l1: 0.0340393\tvalid_1's l1: 0.308669\n",
      "[4800]\ttraining's l1: 0.0317434\tvalid_1's l1: 0.30862\n",
      "[5000]\ttraining's l1: 0.0296341\tvalid_1's l1: 0.308578\n",
      "[5200]\ttraining's l1: 0.0276599\tvalid_1's l1: 0.308524\n",
      "[5400]\ttraining's l1: 0.02584\tvalid_1's l1: 0.308488\n",
      "[5600]\ttraining's l1: 0.0241312\tvalid_1's l1: 0.30847\n",
      "[5800]\ttraining's l1: 0.0225736\tvalid_1's l1: 0.308438\n",
      "[6000]\ttraining's l1: 0.0211287\tvalid_1's l1: 0.308413\n",
      "[6200]\ttraining's l1: 0.019791\tvalid_1's l1: 0.308388\n",
      "[6400]\ttraining's l1: 0.0185852\tvalid_1's l1: 0.308373\n",
      "[6600]\ttraining's l1: 0.0174295\tvalid_1's l1: 0.308357\n",
      "[6800]\ttraining's l1: 0.0163679\tvalid_1's l1: 0.308344\n",
      "[7000]\ttraining's l1: 0.0153559\tvalid_1's l1: 0.308336\n",
      "[7200]\ttraining's l1: 0.014437\tvalid_1's l1: 0.308326\n",
      "[7400]\ttraining's l1: 0.0135786\tvalid_1's l1: 0.308324\n",
      "Early stopping, best iteration is:\n",
      "[7334]\ttraining's l1: 0.0138625\tvalid_1's l1: 0.308319\n",
      "~~~~~~~~~ type name: 1JHN  ~~~~~~~~~\n",
      "validation method: GroupKFold(n_splits=5) groups value: molecule_name\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l1: 0.305276\tvalid_1's l1: 0.800738\n",
      "[400]\ttraining's l1: 0.156614\tvalid_1's l1: 0.787578\n",
      "[600]\ttraining's l1: 0.0895184\tvalid_1's l1: 0.784598\n",
      "[800]\ttraining's l1: 0.0544357\tvalid_1's l1: 0.78378\n",
      "[1000]\ttraining's l1: 0.034443\tvalid_1's l1: 0.783061\n",
      "[1200]\ttraining's l1: 0.0224952\tvalid_1's l1: 0.782749\n",
      "[1400]\ttraining's l1: 0.0149429\tvalid_1's l1: 0.782815\n",
      "Early stopping, best iteration is:\n",
      "[1218]\ttraining's l1: 0.0216598\tvalid_1's l1: 0.782721\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l1: 0.30388\tvalid_1's l1: 0.815802\n",
      "[400]\ttraining's l1: 0.154313\tvalid_1's l1: 0.801852\n",
      "[600]\ttraining's l1: 0.0878523\tvalid_1's l1: 0.799919\n",
      "[800]\ttraining's l1: 0.0534402\tvalid_1's l1: 0.798714\n",
      "[1000]\ttraining's l1: 0.0339779\tvalid_1's l1: 0.798643\n",
      "Early stopping, best iteration is:\n",
      "[897]\ttraining's l1: 0.0428201\tvalid_1's l1: 0.798425\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l1: 0.306297\tvalid_1's l1: 0.791096\n",
      "[400]\ttraining's l1: 0.157055\tvalid_1's l1: 0.775977\n",
      "[600]\ttraining's l1: 0.0895436\tvalid_1's l1: 0.772141\n",
      "[800]\ttraining's l1: 0.0545665\tvalid_1's l1: 0.770535\n",
      "[1000]\ttraining's l1: 0.0346662\tvalid_1's l1: 0.770093\n",
      "[1200]\ttraining's l1: 0.0227066\tvalid_1's l1: 0.769895\n",
      "[1400]\ttraining's l1: 0.0150985\tvalid_1's l1: 0.769858\n",
      "Early stopping, best iteration is:\n",
      "[1262]\ttraining's l1: 0.0200088\tvalid_1's l1: 0.769801\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l1: 0.306184\tvalid_1's l1: 0.775974\n",
      "[400]\ttraining's l1: 0.156823\tvalid_1's l1: 0.760331\n",
      "[600]\ttraining's l1: 0.0894702\tvalid_1's l1: 0.757645\n",
      "[800]\ttraining's l1: 0.0545459\tvalid_1's l1: 0.75617\n",
      "[1000]\ttraining's l1: 0.0344545\tvalid_1's l1: 0.755728\n",
      "[1200]\ttraining's l1: 0.0224909\tvalid_1's l1: 0.755485\n",
      "[1400]\ttraining's l1: 0.0149719\tvalid_1's l1: 0.755505\n",
      "Early stopping, best iteration is:\n",
      "[1363]\ttraining's l1: 0.0161628\tvalid_1's l1: 0.755434\n",
      "fold n°5\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l1: 0.304381\tvalid_1's l1: 0.79373\n",
      "[400]\ttraining's l1: 0.155303\tvalid_1's l1: 0.778159\n",
      "[600]\ttraining's l1: 0.0888643\tvalid_1's l1: 0.77457\n",
      "[800]\ttraining's l1: 0.0540109\tvalid_1's l1: 0.773309\n",
      "[1000]\ttraining's l1: 0.0342582\tvalid_1's l1: 0.773589\n",
      "Early stopping, best iteration is:\n",
      "[802]\ttraining's l1: 0.0537326\tvalid_1's l1: 0.773264\n",
      "~~~~~~~~~ type name: 2JHN  ~~~~~~~~~\n",
      "validation method: GroupKFold(n_splits=5) groups value: molecule_name\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l1: 0.23875\tvalid_1's l1: 0.420618\n",
      "[400]\ttraining's l1: 0.150686\tvalid_1's l1: 0.395375\n",
      "[600]\ttraining's l1: 0.104347\tvalid_1's l1: 0.386059\n",
      "[800]\ttraining's l1: 0.0756447\tvalid_1's l1: 0.381666\n",
      "[1000]\ttraining's l1: 0.0564949\tvalid_1's l1: 0.379311\n",
      "[1200]\ttraining's l1: 0.0430134\tvalid_1's l1: 0.377974\n",
      "[1400]\ttraining's l1: 0.0333675\tvalid_1's l1: 0.377159\n",
      "[1600]\ttraining's l1: 0.0261768\tvalid_1's l1: 0.376611\n",
      "[1800]\ttraining's l1: 0.0207781\tvalid_1's l1: 0.37626\n",
      "[2000]\ttraining's l1: 0.0166735\tvalid_1's l1: 0.375943\n",
      "[2200]\ttraining's l1: 0.013524\tvalid_1's l1: 0.375741\n",
      "[2400]\ttraining's l1: 0.0110009\tvalid_1's l1: 0.375606\n",
      "[2600]\ttraining's l1: 0.00899529\tvalid_1's l1: 0.375515\n",
      "[2800]\ttraining's l1: 0.00742965\tvalid_1's l1: 0.375433\n",
      "[3000]\ttraining's l1: 0.00615949\tvalid_1's l1: 0.375371\n",
      "[3200]\ttraining's l1: 0.00511934\tvalid_1's l1: 0.375341\n",
      "[3400]\ttraining's l1: 0.00436576\tvalid_1's l1: 0.3753\n",
      "[3600]\ttraining's l1: 0.00367199\tvalid_1's l1: 0.375281\n",
      "[3800]\ttraining's l1: 0.0030906\tvalid_1's l1: 0.375251\n",
      "[4000]\ttraining's l1: 0.0026143\tvalid_1's l1: 0.375237\n",
      "[4200]\ttraining's l1: 0.00221619\tvalid_1's l1: 0.375226\n",
      "[4400]\ttraining's l1: 0.00188163\tvalid_1's l1: 0.375221\n",
      "[4600]\ttraining's l1: 0.00160475\tvalid_1's l1: 0.375217\n",
      "[4800]\ttraining's l1: 0.00136451\tvalid_1's l1: 0.375214\n",
      "[5000]\ttraining's l1: 0.00116836\tvalid_1's l1: 0.375215\n",
      "Early stopping, best iteration is:\n",
      "[4830]\ttraining's l1: 0.00133157\tvalid_1's l1: 0.375212\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l1: 0.240969\tvalid_1's l1: 0.418105\n",
      "[400]\ttraining's l1: 0.151317\tvalid_1's l1: 0.391491\n",
      "[600]\ttraining's l1: 0.104909\tvalid_1's l1: 0.38133\n",
      "[800]\ttraining's l1: 0.0761739\tvalid_1's l1: 0.375924\n",
      "[1000]\ttraining's l1: 0.0569191\tvalid_1's l1: 0.373302\n",
      "[1200]\ttraining's l1: 0.043329\tvalid_1's l1: 0.37165\n",
      "[1400]\ttraining's l1: 0.0335448\tvalid_1's l1: 0.370472\n",
      "[1600]\ttraining's l1: 0.0262521\tvalid_1's l1: 0.369785\n",
      "[1800]\ttraining's l1: 0.0208371\tvalid_1's l1: 0.369282\n",
      "[2000]\ttraining's l1: 0.0167555\tvalid_1's l1: 0.36899\n",
      "[2200]\ttraining's l1: 0.0135723\tvalid_1's l1: 0.368777\n",
      "[2400]\ttraining's l1: 0.0110578\tvalid_1's l1: 0.368606\n",
      "[2600]\ttraining's l1: 0.00903018\tvalid_1's l1: 0.368502\n",
      "[2800]\ttraining's l1: 0.00742752\tvalid_1's l1: 0.368385\n",
      "[3000]\ttraining's l1: 0.00616024\tvalid_1's l1: 0.368338\n",
      "[3200]\ttraining's l1: 0.00511048\tvalid_1's l1: 0.368282\n",
      "[3400]\ttraining's l1: 0.00426925\tvalid_1's l1: 0.368248\n",
      "[3600]\ttraining's l1: 0.00358203\tvalid_1's l1: 0.368228\n",
      "[3800]\ttraining's l1: 0.0030182\tvalid_1's l1: 0.368208\n",
      "[4000]\ttraining's l1: 0.00254843\tvalid_1's l1: 0.368183\n",
      "[4200]\ttraining's l1: 0.00216212\tvalid_1's l1: 0.368165\n",
      "[4400]\ttraining's l1: 0.00183793\tvalid_1's l1: 0.368153\n",
      "[4600]\ttraining's l1: 0.00156656\tvalid_1's l1: 0.368143\n",
      "[4800]\ttraining's l1: 0.00133646\tvalid_1's l1: 0.368134\n",
      "[5000]\ttraining's l1: 0.00114831\tvalid_1's l1: 0.368131\n",
      "[5200]\ttraining's l1: 0.00098742\tvalid_1's l1: 0.368126\n",
      "[5400]\ttraining's l1: 0.000849149\tvalid_1's l1: 0.368125\n",
      "[5600]\ttraining's l1: 0.000730489\tvalid_1's l1: 0.368117\n",
      "[5800]\ttraining's l1: 0.000630576\tvalid_1's l1: 0.368113\n",
      "[6000]\ttraining's l1: 0.000544056\tvalid_1's l1: 0.368112\n",
      "[6200]\ttraining's l1: 0.000470281\tvalid_1's l1: 0.368112\n",
      "[6400]\ttraining's l1: 0.000408065\tvalid_1's l1: 0.368111\n",
      "[6600]\ttraining's l1: 0.000355483\tvalid_1's l1: 0.368108\n",
      "[6800]\ttraining's l1: 0.000308924\tvalid_1's l1: 0.368107\n",
      "[7000]\ttraining's l1: 0.000268272\tvalid_1's l1: 0.368106\n",
      "[7200]\ttraining's l1: 0.000234009\tvalid_1's l1: 0.368105\n",
      "[7400]\ttraining's l1: 0.000204173\tvalid_1's l1: 0.368105\n",
      "Early stopping, best iteration is:\n",
      "[7306]\ttraining's l1: 0.00021733\tvalid_1's l1: 0.368105\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l1: 0.239265\tvalid_1's l1: 0.417475\n",
      "[400]\ttraining's l1: 0.151668\tvalid_1's l1: 0.391239\n",
      "[600]\ttraining's l1: 0.104686\tvalid_1's l1: 0.38209\n",
      "[800]\ttraining's l1: 0.0760917\tvalid_1's l1: 0.376829\n",
      "[1000]\ttraining's l1: 0.0568289\tvalid_1's l1: 0.373691\n",
      "[1200]\ttraining's l1: 0.0433575\tvalid_1's l1: 0.372049\n",
      "[1400]\ttraining's l1: 0.0336302\tvalid_1's l1: 0.371135\n",
      "[1600]\ttraining's l1: 0.0264417\tvalid_1's l1: 0.370638\n",
      "[1800]\ttraining's l1: 0.0209829\tvalid_1's l1: 0.370311\n",
      "[2000]\ttraining's l1: 0.0167852\tvalid_1's l1: 0.36998\n",
      "[2200]\ttraining's l1: 0.0135815\tvalid_1's l1: 0.369775\n",
      "[2400]\ttraining's l1: 0.0110372\tvalid_1's l1: 0.369659\n",
      "[2600]\ttraining's l1: 0.00902337\tvalid_1's l1: 0.369557\n",
      "[2800]\ttraining's l1: 0.00742721\tvalid_1's l1: 0.369501\n",
      "[3000]\ttraining's l1: 0.00616275\tvalid_1's l1: 0.369451\n",
      "[3200]\ttraining's l1: 0.00512531\tvalid_1's l1: 0.36941\n",
      "[3400]\ttraining's l1: 0.00428997\tvalid_1's l1: 0.369375\n",
      "[3600]\ttraining's l1: 0.00360238\tvalid_1's l1: 0.369347\n",
      "[3800]\ttraining's l1: 0.0030362\tvalid_1's l1: 0.369321\n",
      "[4000]\ttraining's l1: 0.00256952\tvalid_1's l1: 0.36931\n",
      "[4200]\ttraining's l1: 0.00218426\tvalid_1's l1: 0.369303\n",
      "[4400]\ttraining's l1: 0.00185573\tvalid_1's l1: 0.369295\n",
      "[4600]\ttraining's l1: 0.00158572\tvalid_1's l1: 0.369281\n",
      "[4800]\ttraining's l1: 0.00135418\tvalid_1's l1: 0.369276\n",
      "[5000]\ttraining's l1: 0.00116084\tvalid_1's l1: 0.369274\n",
      "[5200]\ttraining's l1: 0.000998503\tvalid_1's l1: 0.36927\n",
      "[5400]\ttraining's l1: 0.000859273\tvalid_1's l1: 0.369263\n",
      "[5600]\ttraining's l1: 0.000740606\tvalid_1's l1: 0.369258\n",
      "[5800]\ttraining's l1: 0.000639677\tvalid_1's l1: 0.369254\n",
      "[6000]\ttraining's l1: 0.000553074\tvalid_1's l1: 0.369249\n",
      "[6200]\ttraining's l1: 0.000478803\tvalid_1's l1: 0.369246\n",
      "[6400]\ttraining's l1: 0.000416101\tvalid_1's l1: 0.369245\n",
      "[6600]\ttraining's l1: 0.000361835\tvalid_1's l1: 0.369246\n",
      "Early stopping, best iteration is:\n",
      "[6436]\ttraining's l1: 0.000405661\tvalid_1's l1: 0.369244\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l1: 0.240019\tvalid_1's l1: 0.417521\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[400]\ttraining's l1: 0.151844\tvalid_1's l1: 0.392082\n",
      "[600]\ttraining's l1: 0.105076\tvalid_1's l1: 0.381587\n",
      "[800]\ttraining's l1: 0.0762595\tvalid_1's l1: 0.376245\n",
      "[1000]\ttraining's l1: 0.0570973\tvalid_1's l1: 0.373438\n",
      "[1200]\ttraining's l1: 0.0435236\tvalid_1's l1: 0.371857\n",
      "[1400]\ttraining's l1: 0.0337138\tvalid_1's l1: 0.370857\n",
      "[1600]\ttraining's l1: 0.0265167\tvalid_1's l1: 0.370272\n",
      "[1800]\ttraining's l1: 0.0209737\tvalid_1's l1: 0.369934\n",
      "[2000]\ttraining's l1: 0.0168517\tvalid_1's l1: 0.369605\n",
      "[2200]\ttraining's l1: 0.0136697\tvalid_1's l1: 0.369453\n",
      "[2400]\ttraining's l1: 0.0111168\tvalid_1's l1: 0.369309\n",
      "[2600]\ttraining's l1: 0.00909889\tvalid_1's l1: 0.369224\n",
      "[2800]\ttraining's l1: 0.00750564\tvalid_1's l1: 0.369128\n",
      "[3000]\ttraining's l1: 0.00621814\tvalid_1's l1: 0.369072\n",
      "[3200]\ttraining's l1: 0.00516727\tvalid_1's l1: 0.369012\n",
      "[3400]\ttraining's l1: 0.00431782\tvalid_1's l1: 0.36898\n",
      "[3600]\ttraining's l1: 0.00363481\tvalid_1's l1: 0.368951\n",
      "[3800]\ttraining's l1: 0.00306284\tvalid_1's l1: 0.368939\n",
      "[4000]\ttraining's l1: 0.00259325\tvalid_1's l1: 0.368908\n",
      "[4200]\ttraining's l1: 0.00219872\tvalid_1's l1: 0.368903\n",
      "[4400]\ttraining's l1: 0.00187471\tvalid_1's l1: 0.368903\n",
      "[4600]\ttraining's l1: 0.0015996\tvalid_1's l1: 0.368898\n",
      "[4800]\ttraining's l1: 0.00137051\tvalid_1's l1: 0.36889\n",
      "[5000]\ttraining's l1: 0.00125149\tvalid_1's l1: 0.368884\n",
      "[5200]\ttraining's l1: 0.00108739\tvalid_1's l1: 0.368875\n",
      "Early stopping, best iteration is:\n",
      "[5104]\ttraining's l1: 0.00116823\tvalid_1's l1: 0.368873\n",
      "fold n°5\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l1: 0.241065\tvalid_1's l1: 0.413677\n",
      "[400]\ttraining's l1: 0.152274\tvalid_1's l1: 0.38615\n",
      "[600]\ttraining's l1: 0.105215\tvalid_1's l1: 0.376549\n",
      "[800]\ttraining's l1: 0.07603\tvalid_1's l1: 0.371563\n",
      "[1000]\ttraining's l1: 0.0569644\tvalid_1's l1: 0.368607\n",
      "[1200]\ttraining's l1: 0.0434984\tvalid_1's l1: 0.366775\n",
      "[1400]\ttraining's l1: 0.0336716\tvalid_1's l1: 0.365832\n",
      "[1600]\ttraining's l1: 0.0264474\tvalid_1's l1: 0.365273\n",
      "[1800]\ttraining's l1: 0.0210033\tvalid_1's l1: 0.364824\n",
      "[2000]\ttraining's l1: 0.0168896\tvalid_1's l1: 0.36453\n",
      "[2200]\ttraining's l1: 0.0136592\tvalid_1's l1: 0.364279\n",
      "[2400]\ttraining's l1: 0.0110822\tvalid_1's l1: 0.364135\n",
      "[2600]\ttraining's l1: 0.00905982\tvalid_1's l1: 0.364027\n",
      "[2800]\ttraining's l1: 0.00747997\tvalid_1's l1: 0.363943\n",
      "[3000]\ttraining's l1: 0.00620403\tvalid_1's l1: 0.363869\n",
      "[3200]\ttraining's l1: 0.00514617\tvalid_1's l1: 0.363831\n",
      "[3400]\ttraining's l1: 0.00431064\tvalid_1's l1: 0.363805\n",
      "[3600]\ttraining's l1: 0.0036231\tvalid_1's l1: 0.363767\n",
      "[3800]\ttraining's l1: 0.0030516\tvalid_1's l1: 0.363739\n",
      "[4000]\ttraining's l1: 0.0025812\tvalid_1's l1: 0.363716\n",
      "[4200]\ttraining's l1: 0.00219174\tvalid_1's l1: 0.363701\n",
      "[4400]\ttraining's l1: 0.00186274\tvalid_1's l1: 0.363692\n",
      "[4600]\ttraining's l1: 0.00159114\tvalid_1's l1: 0.363684\n",
      "[4800]\ttraining's l1: 0.00135853\tvalid_1's l1: 0.363672\n",
      "[5000]\ttraining's l1: 0.00120787\tvalid_1's l1: 0.363659\n",
      "[5200]\ttraining's l1: 0.00104934\tvalid_1's l1: 0.363656\n",
      "[5400]\ttraining's l1: 0.000903403\tvalid_1's l1: 0.363655\n",
      "[5600]\ttraining's l1: 0.000773975\tvalid_1's l1: 0.363648\n",
      "[5800]\ttraining's l1: 0.000667236\tvalid_1's l1: 0.363646\n",
      "[6000]\ttraining's l1: 0.000574751\tvalid_1's l1: 0.363645\n",
      "[6200]\ttraining's l1: 0.000496539\tvalid_1's l1: 0.363643\n",
      "[6400]\ttraining's l1: 0.00043089\tvalid_1's l1: 0.363644\n",
      "Early stopping, best iteration is:\n",
      "[6258]\ttraining's l1: 0.000477016\tvalid_1's l1: 0.363642\n",
      "~~~~~~~~~ type name: 2JHC  ~~~~~~~~~\n",
      "validation method: GroupKFold(n_splits=5) groups value: molecule_name\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l1: 0.795709\tvalid_1's l1: 0.861086\n",
      "[400]\ttraining's l1: 0.677125\tvalid_1's l1: 0.787403\n",
      "[600]\ttraining's l1: 0.603104\tvalid_1's l1: 0.74937\n",
      "[800]\ttraining's l1: 0.545895\tvalid_1's l1: 0.722264\n",
      "[1000]\ttraining's l1: 0.500799\tvalid_1's l1: 0.703054\n",
      "[1200]\ttraining's l1: 0.46223\tvalid_1's l1: 0.687506\n",
      "[1400]\ttraining's l1: 0.430649\tvalid_1's l1: 0.676425\n",
      "[1600]\ttraining's l1: 0.402968\tvalid_1's l1: 0.667624\n",
      "[1800]\ttraining's l1: 0.378461\tvalid_1's l1: 0.660199\n",
      "[2000]\ttraining's l1: 0.356691\tvalid_1's l1: 0.6543\n",
      "[2200]\ttraining's l1: 0.336315\tvalid_1's l1: 0.648757\n",
      "[2400]\ttraining's l1: 0.317611\tvalid_1's l1: 0.643837\n",
      "[2600]\ttraining's l1: 0.300957\tvalid_1's l1: 0.640007\n",
      "[2800]\ttraining's l1: 0.285397\tvalid_1's l1: 0.636195\n",
      "[3000]\ttraining's l1: 0.271227\tvalid_1's l1: 0.633153\n",
      "[3200]\ttraining's l1: 0.258128\tvalid_1's l1: 0.630476\n",
      "[3400]\ttraining's l1: 0.245776\tvalid_1's l1: 0.628025\n",
      "[3600]\ttraining's l1: 0.234485\tvalid_1's l1: 0.62574\n",
      "[3800]\ttraining's l1: 0.223771\tvalid_1's l1: 0.623391\n",
      "[4000]\ttraining's l1: 0.213838\tvalid_1's l1: 0.6216\n",
      "[4200]\ttraining's l1: 0.204445\tvalid_1's l1: 0.619878\n",
      "[4400]\ttraining's l1: 0.195539\tvalid_1's l1: 0.618371\n",
      "[4600]\ttraining's l1: 0.187208\tvalid_1's l1: 0.616855\n",
      "[4800]\ttraining's l1: 0.17945\tvalid_1's l1: 0.615616\n",
      "[5000]\ttraining's l1: 0.171951\tvalid_1's l1: 0.614379\n",
      "[5200]\ttraining's l1: 0.164983\tvalid_1's l1: 0.613287\n",
      "[5400]\ttraining's l1: 0.158422\tvalid_1's l1: 0.612234\n",
      "[5600]\ttraining's l1: 0.152129\tvalid_1's l1: 0.611387\n",
      "[5800]\ttraining's l1: 0.146004\tvalid_1's l1: 0.610403\n",
      "[6000]\ttraining's l1: 0.140367\tvalid_1's l1: 0.609556\n",
      "[6200]\ttraining's l1: 0.135044\tvalid_1's l1: 0.608756\n",
      "[6400]\ttraining's l1: 0.129932\tvalid_1's l1: 0.608025\n",
      "[6600]\ttraining's l1: 0.125036\tvalid_1's l1: 0.607369\n",
      "[6800]\ttraining's l1: 0.120456\tvalid_1's l1: 0.606771\n",
      "[7000]\ttraining's l1: 0.116045\tvalid_1's l1: 0.606306\n",
      "[7200]\ttraining's l1: 0.11188\tvalid_1's l1: 0.605822\n",
      "[7400]\ttraining's l1: 0.10786\tvalid_1's l1: 0.605276\n",
      "[7600]\ttraining's l1: 0.104005\tvalid_1's l1: 0.604909\n",
      "[7800]\ttraining's l1: 0.100399\tvalid_1's l1: 0.604507\n",
      "[8000]\ttraining's l1: 0.0969006\tvalid_1's l1: 0.604066\n",
      "[8200]\ttraining's l1: 0.0934895\tvalid_1's l1: 0.60373\n",
      "[8400]\ttraining's l1: 0.0902276\tvalid_1's l1: 0.603387\n",
      "[8600]\ttraining's l1: 0.0871697\tvalid_1's l1: 0.602971\n",
      "[8800]\ttraining's l1: 0.0841667\tvalid_1's l1: 0.602659\n",
      "[9000]\ttraining's l1: 0.0812775\tvalid_1's l1: 0.602377\n",
      "[9200]\ttraining's l1: 0.078594\tvalid_1's l1: 0.602151\n",
      "[9400]\ttraining's l1: 0.0759287\tvalid_1's l1: 0.601927\n",
      "[9600]\ttraining's l1: 0.0734295\tvalid_1's l1: 0.601674\n",
      "[9800]\ttraining's l1: 0.0709916\tvalid_1's l1: 0.601474\n",
      "[10000]\ttraining's l1: 0.0687145\tvalid_1's l1: 0.601244\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.0687145\tvalid_1's l1: 0.601244\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l1: 0.799808\tvalid_1's l1: 0.865488\n",
      "[400]\ttraining's l1: 0.680784\tvalid_1's l1: 0.79182\n",
      "[600]\ttraining's l1: 0.605244\tvalid_1's l1: 0.75255\n",
      "[800]\ttraining's l1: 0.547611\tvalid_1's l1: 0.725708\n",
      "[1000]\ttraining's l1: 0.503132\tvalid_1's l1: 0.707601\n",
      "[1200]\ttraining's l1: 0.464972\tvalid_1's l1: 0.69304\n",
      "[1400]\ttraining's l1: 0.432054\tvalid_1's l1: 0.681614\n",
      "[1600]\ttraining's l1: 0.403763\tvalid_1's l1: 0.672635\n",
      "[1800]\ttraining's l1: 0.378671\tvalid_1's l1: 0.664946\n",
      "[2000]\ttraining's l1: 0.355901\tvalid_1's l1: 0.657928\n",
      "[2200]\ttraining's l1: 0.335328\tvalid_1's l1: 0.651915\n",
      "[2400]\ttraining's l1: 0.31699\tvalid_1's l1: 0.64757\n",
      "[2600]\ttraining's l1: 0.30046\tvalid_1's l1: 0.643483\n",
      "[2800]\ttraining's l1: 0.285136\tvalid_1's l1: 0.639883\n",
      "[3000]\ttraining's l1: 0.270878\tvalid_1's l1: 0.636747\n",
      "[3200]\ttraining's l1: 0.257975\tvalid_1's l1: 0.634072\n",
      "[3400]\ttraining's l1: 0.245575\tvalid_1's l1: 0.631571\n",
      "[3600]\ttraining's l1: 0.234199\tvalid_1's l1: 0.62916\n",
      "[3800]\ttraining's l1: 0.223674\tvalid_1's l1: 0.627011\n",
      "[4000]\ttraining's l1: 0.213668\tvalid_1's l1: 0.625226\n",
      "[4200]\ttraining's l1: 0.2043\tvalid_1's l1: 0.623513\n",
      "[4400]\ttraining's l1: 0.195577\tvalid_1's l1: 0.621964\n",
      "[4600]\ttraining's l1: 0.18723\tvalid_1's l1: 0.620612\n",
      "[4800]\ttraining's l1: 0.1794\tvalid_1's l1: 0.619242\n",
      "[5000]\ttraining's l1: 0.172156\tvalid_1's l1: 0.618076\n",
      "[5200]\ttraining's l1: 0.165143\tvalid_1's l1: 0.616972\n",
      "[5400]\ttraining's l1: 0.158436\tvalid_1's l1: 0.615832\n",
      "[5600]\ttraining's l1: 0.152153\tvalid_1's l1: 0.61492\n",
      "[5800]\ttraining's l1: 0.146157\tvalid_1's l1: 0.614014\n",
      "[6000]\ttraining's l1: 0.140492\tvalid_1's l1: 0.613163\n",
      "[6200]\ttraining's l1: 0.135146\tvalid_1's l1: 0.612448\n",
      "[6400]\ttraining's l1: 0.130062\tvalid_1's l1: 0.611759\n",
      "[6600]\ttraining's l1: 0.125248\tvalid_1's l1: 0.611083\n",
      "[6800]\ttraining's l1: 0.120622\tvalid_1's l1: 0.610494\n",
      "[7000]\ttraining's l1: 0.116189\tvalid_1's l1: 0.609903\n",
      "[7200]\ttraining's l1: 0.111901\tvalid_1's l1: 0.609399\n",
      "[7400]\ttraining's l1: 0.107826\tvalid_1's l1: 0.608872\n",
      "[7600]\ttraining's l1: 0.103971\tvalid_1's l1: 0.608474\n",
      "[7800]\ttraining's l1: 0.100209\tvalid_1's l1: 0.608037\n",
      "[8000]\ttraining's l1: 0.0967536\tvalid_1's l1: 0.60763\n",
      "[8200]\ttraining's l1: 0.0933802\tvalid_1's l1: 0.607224\n",
      "[8400]\ttraining's l1: 0.0901548\tvalid_1's l1: 0.606827\n",
      "[8600]\ttraining's l1: 0.0870731\tvalid_1's l1: 0.606501\n",
      "[8800]\ttraining's l1: 0.0841159\tvalid_1's l1: 0.606181\n",
      "[9000]\ttraining's l1: 0.0812738\tvalid_1's l1: 0.605833\n",
      "[9200]\ttraining's l1: 0.0785389\tvalid_1's l1: 0.605528\n",
      "[9400]\ttraining's l1: 0.0759035\tvalid_1's l1: 0.605266\n",
      "[9600]\ttraining's l1: 0.0734151\tvalid_1's l1: 0.604998\n",
      "[9800]\ttraining's l1: 0.0710184\tvalid_1's l1: 0.604792\n",
      "[10000]\ttraining's l1: 0.0687238\tvalid_1's l1: 0.604541\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.0687238\tvalid_1's l1: 0.604541\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l1: 0.79497\tvalid_1's l1: 0.867807\n",
      "[400]\ttraining's l1: 0.676853\tvalid_1's l1: 0.794837\n",
      "[600]\ttraining's l1: 0.602007\tvalid_1's l1: 0.755188\n",
      "[800]\ttraining's l1: 0.546052\tvalid_1's l1: 0.729176\n",
      "[1000]\ttraining's l1: 0.500916\tvalid_1's l1: 0.709991\n",
      "[1200]\ttraining's l1: 0.463345\tvalid_1's l1: 0.695401\n",
      "[1400]\ttraining's l1: 0.431172\tvalid_1's l1: 0.683465\n",
      "[1600]\ttraining's l1: 0.403044\tvalid_1's l1: 0.674439\n",
      "[1800]\ttraining's l1: 0.378534\tvalid_1's l1: 0.667426\n",
      "[2000]\ttraining's l1: 0.355986\tvalid_1's l1: 0.660721\n",
      "[2200]\ttraining's l1: 0.335549\tvalid_1's l1: 0.655139\n",
      "[2400]\ttraining's l1: 0.317117\tvalid_1's l1: 0.650136\n",
      "[2600]\ttraining's l1: 0.300503\tvalid_1's l1: 0.646425\n",
      "[2800]\ttraining's l1: 0.285085\tvalid_1's l1: 0.642544\n",
      "[3000]\ttraining's l1: 0.270971\tvalid_1's l1: 0.639264\n",
      "[3200]\ttraining's l1: 0.25787\tvalid_1's l1: 0.636577\n",
      "[3400]\ttraining's l1: 0.245671\tvalid_1's l1: 0.634244\n",
      "[3600]\ttraining's l1: 0.234269\tvalid_1's l1: 0.631846\n",
      "[3800]\ttraining's l1: 0.223751\tvalid_1's l1: 0.629858\n",
      "[4000]\ttraining's l1: 0.2136\tvalid_1's l1: 0.627838\n",
      "[4200]\ttraining's l1: 0.204293\tvalid_1's l1: 0.626169\n",
      "[4400]\ttraining's l1: 0.195413\tvalid_1's l1: 0.624685\n",
      "[4600]\ttraining's l1: 0.18716\tvalid_1's l1: 0.623222\n",
      "[4800]\ttraining's l1: 0.179385\tvalid_1's l1: 0.621931\n",
      "[5000]\ttraining's l1: 0.172089\tvalid_1's l1: 0.620613\n",
      "[5200]\ttraining's l1: 0.165166\tvalid_1's l1: 0.619372\n",
      "[5400]\ttraining's l1: 0.158466\tvalid_1's l1: 0.61828\n",
      "[5600]\ttraining's l1: 0.152135\tvalid_1's l1: 0.617366\n",
      "[5800]\ttraining's l1: 0.146156\tvalid_1's l1: 0.616482\n",
      "[6000]\ttraining's l1: 0.14046\tvalid_1's l1: 0.615599\n",
      "[6200]\ttraining's l1: 0.13512\tvalid_1's l1: 0.614846\n",
      "[6400]\ttraining's l1: 0.130055\tvalid_1's l1: 0.614157\n",
      "[6600]\ttraining's l1: 0.125204\tvalid_1's l1: 0.613467\n",
      "[6800]\ttraining's l1: 0.120681\tvalid_1's l1: 0.612903\n",
      "[7000]\ttraining's l1: 0.116281\tvalid_1's l1: 0.612388\n",
      "[7200]\ttraining's l1: 0.111981\tvalid_1's l1: 0.611774\n",
      "[7400]\ttraining's l1: 0.107947\tvalid_1's l1: 0.611254\n",
      "[7600]\ttraining's l1: 0.104095\tvalid_1's l1: 0.610801\n",
      "[7800]\ttraining's l1: 0.100339\tvalid_1's l1: 0.610375\n",
      "[8000]\ttraining's l1: 0.096877\tvalid_1's l1: 0.609933\n",
      "[8200]\ttraining's l1: 0.0935241\tvalid_1's l1: 0.609556\n",
      "[8400]\ttraining's l1: 0.0902802\tvalid_1's l1: 0.609262\n",
      "[8600]\ttraining's l1: 0.0871327\tvalid_1's l1: 0.608874\n",
      "[8800]\ttraining's l1: 0.0841753\tvalid_1's l1: 0.608553\n",
      "[9000]\ttraining's l1: 0.0813168\tvalid_1's l1: 0.608215\n",
      "[9200]\ttraining's l1: 0.0785811\tvalid_1's l1: 0.607923\n",
      "[9400]\ttraining's l1: 0.0759523\tvalid_1's l1: 0.60764\n",
      "[9600]\ttraining's l1: 0.07348\tvalid_1's l1: 0.607369\n",
      "[9800]\ttraining's l1: 0.071104\tvalid_1's l1: 0.60719\n",
      "[10000]\ttraining's l1: 0.0688124\tvalid_1's l1: 0.606938\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.0688124\tvalid_1's l1: 0.606938\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l1: 0.797805\tvalid_1's l1: 0.864742\n",
      "[400]\ttraining's l1: 0.678516\tvalid_1's l1: 0.789348\n",
      "[600]\ttraining's l1: 0.604652\tvalid_1's l1: 0.750262\n",
      "[800]\ttraining's l1: 0.548733\tvalid_1's l1: 0.723832\n",
      "[1000]\ttraining's l1: 0.504351\tvalid_1's l1: 0.704735\n",
      "[1200]\ttraining's l1: 0.466584\tvalid_1's l1: 0.690285\n",
      "[1400]\ttraining's l1: 0.43406\tvalid_1's l1: 0.67909\n",
      "[1600]\ttraining's l1: 0.405346\tvalid_1's l1: 0.669884\n",
      "[1800]\ttraining's l1: 0.380296\tvalid_1's l1: 0.662613\n",
      "[2000]\ttraining's l1: 0.357619\tvalid_1's l1: 0.655744\n",
      "[2200]\ttraining's l1: 0.337476\tvalid_1's l1: 0.650222\n",
      "[2400]\ttraining's l1: 0.318812\tvalid_1's l1: 0.645476\n",
      "[2600]\ttraining's l1: 0.302043\tvalid_1's l1: 0.641538\n",
      "[2800]\ttraining's l1: 0.286599\tvalid_1's l1: 0.637667\n",
      "[3000]\ttraining's l1: 0.272321\tvalid_1's l1: 0.634083\n",
      "[3200]\ttraining's l1: 0.259202\tvalid_1's l1: 0.631054\n",
      "[3400]\ttraining's l1: 0.247064\tvalid_1's l1: 0.628354\n",
      "[3600]\ttraining's l1: 0.235835\tvalid_1's l1: 0.626155\n",
      "[3800]\ttraining's l1: 0.225032\tvalid_1's l1: 0.623913\n",
      "[4000]\ttraining's l1: 0.215045\tvalid_1's l1: 0.622073\n",
      "[4200]\ttraining's l1: 0.205686\tvalid_1's l1: 0.62028\n",
      "[4400]\ttraining's l1: 0.196705\tvalid_1's l1: 0.618696\n",
      "[4600]\ttraining's l1: 0.188432\tvalid_1's l1: 0.61722\n",
      "[4800]\ttraining's l1: 0.180517\tvalid_1's l1: 0.615957\n",
      "[5000]\ttraining's l1: 0.173021\tvalid_1's l1: 0.614817\n",
      "[5200]\ttraining's l1: 0.166055\tvalid_1's l1: 0.613707\n",
      "[5400]\ttraining's l1: 0.15929\tvalid_1's l1: 0.612653\n",
      "[5600]\ttraining's l1: 0.152937\tvalid_1's l1: 0.611783\n",
      "[5800]\ttraining's l1: 0.146969\tvalid_1's l1: 0.610906\n",
      "[6000]\ttraining's l1: 0.141222\tvalid_1's l1: 0.610064\n",
      "[6200]\ttraining's l1: 0.135839\tvalid_1's l1: 0.609385\n",
      "[6400]\ttraining's l1: 0.130643\tvalid_1's l1: 0.608644\n",
      "[6600]\ttraining's l1: 0.125667\tvalid_1's l1: 0.607942\n",
      "[6800]\ttraining's l1: 0.121023\tvalid_1's l1: 0.607376\n",
      "[7000]\ttraining's l1: 0.116618\tvalid_1's l1: 0.606829\n",
      "[7200]\ttraining's l1: 0.112377\tvalid_1's l1: 0.606277\n",
      "[7400]\ttraining's l1: 0.108296\tvalid_1's l1: 0.605774\n",
      "[7600]\ttraining's l1: 0.104387\tvalid_1's l1: 0.605241\n",
      "[7800]\ttraining's l1: 0.100697\tvalid_1's l1: 0.604817\n",
      "[8000]\ttraining's l1: 0.0971654\tvalid_1's l1: 0.604431\n",
      "[8200]\ttraining's l1: 0.0937772\tvalid_1's l1: 0.604074\n",
      "[8400]\ttraining's l1: 0.0905958\tvalid_1's l1: 0.603711\n",
      "[8600]\ttraining's l1: 0.0874752\tvalid_1's l1: 0.603307\n",
      "[8800]\ttraining's l1: 0.0844558\tvalid_1's l1: 0.603037\n",
      "[9000]\ttraining's l1: 0.0815799\tvalid_1's l1: 0.602723\n",
      "[9200]\ttraining's l1: 0.0788174\tvalid_1's l1: 0.602436\n",
      "[9400]\ttraining's l1: 0.0762258\tvalid_1's l1: 0.60218\n",
      "[9600]\ttraining's l1: 0.0737273\tvalid_1's l1: 0.601895\n",
      "[9800]\ttraining's l1: 0.0712938\tvalid_1's l1: 0.601691\n",
      "[10000]\ttraining's l1: 0.0689732\tvalid_1's l1: 0.601476\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.0689732\tvalid_1's l1: 0.601476\n",
      "fold n°5\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l1: 0.800716\tvalid_1's l1: 0.866519\n",
      "[400]\ttraining's l1: 0.679944\tvalid_1's l1: 0.789257\n",
      "[600]\ttraining's l1: 0.603518\tvalid_1's l1: 0.749502\n",
      "[800]\ttraining's l1: 0.546877\tvalid_1's l1: 0.7227\n",
      "[1000]\ttraining's l1: 0.501629\tvalid_1's l1: 0.7035\n",
      "[1200]\ttraining's l1: 0.463267\tvalid_1's l1: 0.68883\n",
      "[1400]\ttraining's l1: 0.430454\tvalid_1's l1: 0.677153\n",
      "[1600]\ttraining's l1: 0.403192\tvalid_1's l1: 0.668621\n",
      "[1800]\ttraining's l1: 0.378391\tvalid_1's l1: 0.661159\n",
      "[2000]\ttraining's l1: 0.35613\tvalid_1's l1: 0.654281\n",
      "[2200]\ttraining's l1: 0.336236\tvalid_1's l1: 0.648887\n",
      "[2400]\ttraining's l1: 0.317785\tvalid_1's l1: 0.644084\n",
      "[2600]\ttraining's l1: 0.301105\tvalid_1's l1: 0.639968\n",
      "[2800]\ttraining's l1: 0.285483\tvalid_1's l1: 0.63619\n",
      "[3000]\ttraining's l1: 0.271195\tvalid_1's l1: 0.633011\n",
      "[3200]\ttraining's l1: 0.258088\tvalid_1's l1: 0.63027\n",
      "[3400]\ttraining's l1: 0.245846\tvalid_1's l1: 0.627791\n",
      "[3600]\ttraining's l1: 0.234438\tvalid_1's l1: 0.625285\n",
      "[3800]\ttraining's l1: 0.223784\tvalid_1's l1: 0.62302\n",
      "[4000]\ttraining's l1: 0.213768\tvalid_1's l1: 0.621058\n",
      "[4200]\ttraining's l1: 0.20438\tvalid_1's l1: 0.619355\n",
      "[4400]\ttraining's l1: 0.195538\tvalid_1's l1: 0.617836\n",
      "[4600]\ttraining's l1: 0.187235\tvalid_1's l1: 0.616502\n",
      "[4800]\ttraining's l1: 0.179344\tvalid_1's l1: 0.615364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5000]\ttraining's l1: 0.171942\tvalid_1's l1: 0.614083\n",
      "[5200]\ttraining's l1: 0.164938\tvalid_1's l1: 0.61295\n",
      "[5400]\ttraining's l1: 0.158279\tvalid_1's l1: 0.611931\n",
      "[5600]\ttraining's l1: 0.15207\tvalid_1's l1: 0.610996\n",
      "[5800]\ttraining's l1: 0.146064\tvalid_1's l1: 0.61016\n",
      "[6000]\ttraining's l1: 0.14045\tvalid_1's l1: 0.609366\n",
      "[6200]\ttraining's l1: 0.135049\tvalid_1's l1: 0.608561\n",
      "[6400]\ttraining's l1: 0.129924\tvalid_1's l1: 0.60791\n",
      "[6600]\ttraining's l1: 0.125123\tvalid_1's l1: 0.607319\n",
      "[6800]\ttraining's l1: 0.120455\tvalid_1's l1: 0.606706\n",
      "[7000]\ttraining's l1: 0.116019\tvalid_1's l1: 0.606104\n",
      "[7200]\ttraining's l1: 0.11182\tvalid_1's l1: 0.60556\n",
      "[7400]\ttraining's l1: 0.107807\tvalid_1's l1: 0.605027\n",
      "[7600]\ttraining's l1: 0.10401\tvalid_1's l1: 0.604579\n",
      "[7800]\ttraining's l1: 0.100323\tvalid_1's l1: 0.604167\n",
      "[8000]\ttraining's l1: 0.0967847\tvalid_1's l1: 0.603728\n",
      "[8200]\ttraining's l1: 0.0933951\tvalid_1's l1: 0.603375\n",
      "[8400]\ttraining's l1: 0.0901854\tvalid_1's l1: 0.603076\n",
      "[8600]\ttraining's l1: 0.0870784\tvalid_1's l1: 0.602705\n",
      "[8800]\ttraining's l1: 0.0840597\tvalid_1's l1: 0.602389\n",
      "[9000]\ttraining's l1: 0.0811787\tvalid_1's l1: 0.602127\n",
      "[9200]\ttraining's l1: 0.0784385\tvalid_1's l1: 0.601844\n",
      "[9400]\ttraining's l1: 0.0758359\tvalid_1's l1: 0.601573\n",
      "[9600]\ttraining's l1: 0.073305\tvalid_1's l1: 0.601308\n",
      "[9800]\ttraining's l1: 0.0709415\tvalid_1's l1: 0.601077\n",
      "[10000]\ttraining's l1: 0.0686722\tvalid_1's l1: 0.600836\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.0686722\tvalid_1's l1: 0.600836\n",
      "~~~~~~~~~ type name: 3JHH  ~~~~~~~~~\n",
      "validation method: GroupKFold(n_splits=5) groups value: molecule_name\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l1: 0.421497\tvalid_1's l1: 0.483314\n",
      "[400]\ttraining's l1: 0.344752\tvalid_1's l1: 0.441178\n",
      "[600]\ttraining's l1: 0.29811\tvalid_1's l1: 0.422051\n",
      "[800]\ttraining's l1: 0.263184\tvalid_1's l1: 0.408441\n",
      "[1000]\ttraining's l1: 0.236167\tvalid_1's l1: 0.399429\n",
      "[1200]\ttraining's l1: 0.21429\tvalid_1's l1: 0.393055\n",
      "[1400]\ttraining's l1: 0.195752\tvalid_1's l1: 0.388346\n",
      "[1600]\ttraining's l1: 0.179682\tvalid_1's l1: 0.384564\n",
      "[1800]\ttraining's l1: 0.165817\tvalid_1's l1: 0.381592\n",
      "[2000]\ttraining's l1: 0.153516\tvalid_1's l1: 0.379042\n",
      "[2200]\ttraining's l1: 0.14249\tvalid_1's l1: 0.377048\n",
      "[2400]\ttraining's l1: 0.132752\tvalid_1's l1: 0.375412\n",
      "[2600]\ttraining's l1: 0.12392\tvalid_1's l1: 0.373914\n",
      "[2800]\ttraining's l1: 0.115903\tvalid_1's l1: 0.372523\n",
      "[3000]\ttraining's l1: 0.108571\tvalid_1's l1: 0.371447\n",
      "[3200]\ttraining's l1: 0.101943\tvalid_1's l1: 0.370625\n",
      "[3400]\ttraining's l1: 0.0957432\tvalid_1's l1: 0.369892\n",
      "[3600]\ttraining's l1: 0.0900108\tvalid_1's l1: 0.369129\n",
      "[3800]\ttraining's l1: 0.0847945\tvalid_1's l1: 0.368503\n",
      "[4000]\ttraining's l1: 0.0799663\tvalid_1's l1: 0.367942\n",
      "[4200]\ttraining's l1: 0.0755276\tvalid_1's l1: 0.367412\n",
      "[4400]\ttraining's l1: 0.0714254\tvalid_1's l1: 0.367048\n",
      "[4600]\ttraining's l1: 0.0675208\tvalid_1's l1: 0.36661\n",
      "[4800]\ttraining's l1: 0.0639161\tvalid_1's l1: 0.366217\n",
      "[5000]\ttraining's l1: 0.0605936\tvalid_1's l1: 0.365931\n",
      "[5200]\ttraining's l1: 0.0573942\tvalid_1's l1: 0.36567\n",
      "[5400]\ttraining's l1: 0.0544341\tvalid_1's l1: 0.365483\n",
      "[5600]\ttraining's l1: 0.051619\tvalid_1's l1: 0.36526\n",
      "[5800]\ttraining's l1: 0.0490012\tvalid_1's l1: 0.365088\n",
      "[6000]\ttraining's l1: 0.0465595\tvalid_1's l1: 0.364956\n",
      "[6200]\ttraining's l1: 0.0442631\tvalid_1's l1: 0.364821\n",
      "[6400]\ttraining's l1: 0.0421512\tvalid_1's l1: 0.364657\n",
      "[6600]\ttraining's l1: 0.0401514\tvalid_1's l1: 0.364501\n",
      "[6800]\ttraining's l1: 0.0382557\tvalid_1's l1: 0.364386\n",
      "[7000]\ttraining's l1: 0.0364463\tvalid_1's l1: 0.364293\n",
      "[7200]\ttraining's l1: 0.034741\tvalid_1's l1: 0.364189\n",
      "[7400]\ttraining's l1: 0.033153\tvalid_1's l1: 0.364111\n",
      "[7600]\ttraining's l1: 0.0316395\tvalid_1's l1: 0.364033\n",
      "[7800]\ttraining's l1: 0.0301961\tvalid_1's l1: 0.363947\n",
      "[8000]\ttraining's l1: 0.0288496\tvalid_1's l1: 0.363857\n",
      "[8200]\ttraining's l1: 0.0275621\tvalid_1's l1: 0.363797\n",
      "[8400]\ttraining's l1: 0.02631\tvalid_1's l1: 0.363754\n",
      "[8600]\ttraining's l1: 0.0251605\tvalid_1's l1: 0.363703\n",
      "[8800]\ttraining's l1: 0.0240694\tvalid_1's l1: 0.363653\n",
      "[9000]\ttraining's l1: 0.0230156\tvalid_1's l1: 0.363601\n",
      "[9200]\ttraining's l1: 0.0220411\tvalid_1's l1: 0.363535\n",
      "[9400]\ttraining's l1: 0.0210953\tvalid_1's l1: 0.363491\n",
      "[9600]\ttraining's l1: 0.0202039\tvalid_1's l1: 0.363458\n",
      "[9800]\ttraining's l1: 0.0193453\tvalid_1's l1: 0.363416\n",
      "[10000]\ttraining's l1: 0.0185396\tvalid_1's l1: 0.363397\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.0185396\tvalid_1's l1: 0.363397\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l1: 0.425291\tvalid_1's l1: 0.482597\n",
      "[400]\ttraining's l1: 0.347314\tvalid_1's l1: 0.44034\n",
      "[600]\ttraining's l1: 0.298666\tvalid_1's l1: 0.418711\n",
      "[800]\ttraining's l1: 0.26421\tvalid_1's l1: 0.40607\n",
      "[1000]\ttraining's l1: 0.23711\tvalid_1's l1: 0.397679\n",
      "[1200]\ttraining's l1: 0.214856\tvalid_1's l1: 0.391191\n",
      "[1400]\ttraining's l1: 0.196004\tvalid_1's l1: 0.386324\n",
      "[1600]\ttraining's l1: 0.180148\tvalid_1's l1: 0.382597\n",
      "[1800]\ttraining's l1: 0.166095\tvalid_1's l1: 0.3797\n",
      "[2000]\ttraining's l1: 0.153833\tvalid_1's l1: 0.377125\n",
      "[2200]\ttraining's l1: 0.142924\tvalid_1's l1: 0.375036\n",
      "[2400]\ttraining's l1: 0.132982\tvalid_1's l1: 0.373361\n",
      "[2600]\ttraining's l1: 0.124177\tvalid_1's l1: 0.371895\n",
      "[2800]\ttraining's l1: 0.116111\tvalid_1's l1: 0.370778\n",
      "[3000]\ttraining's l1: 0.108759\tvalid_1's l1: 0.36978\n",
      "[3200]\ttraining's l1: 0.10205\tvalid_1's l1: 0.369042\n",
      "[3400]\ttraining's l1: 0.0959256\tvalid_1's l1: 0.368313\n",
      "[3600]\ttraining's l1: 0.0903123\tvalid_1's l1: 0.367645\n",
      "[3800]\ttraining's l1: 0.0851512\tvalid_1's l1: 0.36694\n",
      "[4000]\ttraining's l1: 0.0803311\tvalid_1's l1: 0.366362\n",
      "[4200]\ttraining's l1: 0.0757985\tvalid_1's l1: 0.36586\n",
      "[4400]\ttraining's l1: 0.0715909\tvalid_1's l1: 0.365415\n",
      "[4600]\ttraining's l1: 0.0677284\tvalid_1's l1: 0.365086\n",
      "[4800]\ttraining's l1: 0.0641474\tvalid_1's l1: 0.364783\n",
      "[5000]\ttraining's l1: 0.0607908\tvalid_1's l1: 0.364525\n",
      "[5200]\ttraining's l1: 0.0576254\tvalid_1's l1: 0.36429\n",
      "[5400]\ttraining's l1: 0.0546095\tvalid_1's l1: 0.364045\n",
      "[5600]\ttraining's l1: 0.0518394\tvalid_1's l1: 0.363853\n",
      "[5800]\ttraining's l1: 0.0492165\tvalid_1's l1: 0.363672\n",
      "[6000]\ttraining's l1: 0.0468025\tvalid_1's l1: 0.363512\n",
      "[6200]\ttraining's l1: 0.0445396\tvalid_1's l1: 0.363371\n",
      "[6400]\ttraining's l1: 0.0423874\tvalid_1's l1: 0.363201\n",
      "[6600]\ttraining's l1: 0.0403737\tvalid_1's l1: 0.363087\n",
      "[6800]\ttraining's l1: 0.038433\tvalid_1's l1: 0.36301\n",
      "[7000]\ttraining's l1: 0.0366008\tvalid_1's l1: 0.362901\n",
      "[7200]\ttraining's l1: 0.0348918\tvalid_1's l1: 0.362835\n",
      "[7400]\ttraining's l1: 0.0332875\tvalid_1's l1: 0.362724\n",
      "[7600]\ttraining's l1: 0.0317735\tvalid_1's l1: 0.362645\n",
      "[7800]\ttraining's l1: 0.030324\tvalid_1's l1: 0.36256\n",
      "[8000]\ttraining's l1: 0.0289592\tvalid_1's l1: 0.362506\n",
      "[8200]\ttraining's l1: 0.0276446\tvalid_1's l1: 0.362445\n",
      "[8400]\ttraining's l1: 0.0264181\tvalid_1's l1: 0.36238\n",
      "[8600]\ttraining's l1: 0.0252547\tvalid_1's l1: 0.362339\n",
      "[8800]\ttraining's l1: 0.0241393\tvalid_1's l1: 0.362313\n",
      "[9000]\ttraining's l1: 0.0230775\tvalid_1's l1: 0.362279\n",
      "[9200]\ttraining's l1: 0.0220845\tvalid_1's l1: 0.362232\n",
      "[9400]\ttraining's l1: 0.021135\tvalid_1's l1: 0.362188\n",
      "[9600]\ttraining's l1: 0.0202536\tvalid_1's l1: 0.362156\n",
      "[9800]\ttraining's l1: 0.0194103\tvalid_1's l1: 0.362135\n",
      "[10000]\ttraining's l1: 0.0186138\tvalid_1's l1: 0.36209\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.0186138\tvalid_1's l1: 0.36209\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l1: 0.426358\tvalid_1's l1: 0.488039\n",
      "[400]\ttraining's l1: 0.346327\tvalid_1's l1: 0.443236\n",
      "[600]\ttraining's l1: 0.298939\tvalid_1's l1: 0.423402\n",
      "[800]\ttraining's l1: 0.263728\tvalid_1's l1: 0.409937\n",
      "[1000]\ttraining's l1: 0.236845\tvalid_1's l1: 0.401716\n",
      "[1200]\ttraining's l1: 0.214629\tvalid_1's l1: 0.395471\n",
      "[1400]\ttraining's l1: 0.19612\tvalid_1's l1: 0.390571\n",
      "[1600]\ttraining's l1: 0.179968\tvalid_1's l1: 0.387003\n",
      "[1800]\ttraining's l1: 0.165894\tvalid_1's l1: 0.383829\n",
      "[2000]\ttraining's l1: 0.15362\tvalid_1's l1: 0.381187\n",
      "[2200]\ttraining's l1: 0.142562\tvalid_1's l1: 0.378958\n",
      "[2400]\ttraining's l1: 0.132771\tvalid_1's l1: 0.377392\n",
      "[2600]\ttraining's l1: 0.123818\tvalid_1's l1: 0.375796\n",
      "[2800]\ttraining's l1: 0.115779\tvalid_1's l1: 0.374528\n",
      "[3000]\ttraining's l1: 0.108472\tvalid_1's l1: 0.373528\n",
      "[3200]\ttraining's l1: 0.101809\tvalid_1's l1: 0.372588\n",
      "[3400]\ttraining's l1: 0.0956367\tvalid_1's l1: 0.371822\n",
      "[3600]\ttraining's l1: 0.0899742\tvalid_1's l1: 0.371073\n",
      "[3800]\ttraining's l1: 0.0847325\tvalid_1's l1: 0.370441\n",
      "[4000]\ttraining's l1: 0.0799049\tvalid_1's l1: 0.369974\n",
      "[4200]\ttraining's l1: 0.0754595\tvalid_1's l1: 0.369495\n",
      "[4400]\ttraining's l1: 0.0712796\tvalid_1's l1: 0.369034\n",
      "[4600]\ttraining's l1: 0.0674787\tvalid_1's l1: 0.368647\n",
      "[4800]\ttraining's l1: 0.0638987\tvalid_1's l1: 0.368284\n",
      "[5000]\ttraining's l1: 0.0606025\tvalid_1's l1: 0.36803\n",
      "[5200]\ttraining's l1: 0.0574576\tvalid_1's l1: 0.367768\n",
      "[5400]\ttraining's l1: 0.0544483\tvalid_1's l1: 0.367528\n",
      "[5600]\ttraining's l1: 0.0516557\tvalid_1's l1: 0.367361\n",
      "[5800]\ttraining's l1: 0.049071\tvalid_1's l1: 0.367198\n",
      "[6000]\ttraining's l1: 0.046654\tvalid_1's l1: 0.367027\n",
      "[6200]\ttraining's l1: 0.0443966\tvalid_1's l1: 0.366883\n",
      "[6400]\ttraining's l1: 0.0422755\tvalid_1's l1: 0.366738\n",
      "[6600]\ttraining's l1: 0.0402876\tvalid_1's l1: 0.366614\n",
      "[6800]\ttraining's l1: 0.0383669\tvalid_1's l1: 0.36648\n",
      "[7000]\ttraining's l1: 0.0365249\tvalid_1's l1: 0.366409\n",
      "[7200]\ttraining's l1: 0.0348283\tvalid_1's l1: 0.366302\n",
      "[7400]\ttraining's l1: 0.0332309\tvalid_1's l1: 0.36623\n",
      "[7600]\ttraining's l1: 0.0317034\tvalid_1's l1: 0.366159\n",
      "[7800]\ttraining's l1: 0.0302771\tvalid_1's l1: 0.366088\n",
      "[8000]\ttraining's l1: 0.0289292\tvalid_1's l1: 0.366024\n",
      "[8200]\ttraining's l1: 0.0276295\tvalid_1's l1: 0.365977\n",
      "[8400]\ttraining's l1: 0.0263866\tvalid_1's l1: 0.365932\n",
      "[8600]\ttraining's l1: 0.0252077\tvalid_1's l1: 0.365879\n",
      "[8800]\ttraining's l1: 0.0240816\tvalid_1's l1: 0.365827\n",
      "[9000]\ttraining's l1: 0.0230346\tvalid_1's l1: 0.365794\n",
      "[9200]\ttraining's l1: 0.0220201\tvalid_1's l1: 0.36574\n",
      "[9400]\ttraining's l1: 0.0210799\tvalid_1's l1: 0.365715\n",
      "[9600]\ttraining's l1: 0.0201895\tvalid_1's l1: 0.365683\n",
      "[9800]\ttraining's l1: 0.0193235\tvalid_1's l1: 0.365655\n",
      "[10000]\ttraining's l1: 0.0185214\tvalid_1's l1: 0.365617\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.0185214\tvalid_1's l1: 0.365617\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l1: 0.425091\tvalid_1's l1: 0.486106\n",
      "[400]\ttraining's l1: 0.346374\tvalid_1's l1: 0.442093\n",
      "[600]\ttraining's l1: 0.298389\tvalid_1's l1: 0.420851\n",
      "[800]\ttraining's l1: 0.263459\tvalid_1's l1: 0.407398\n",
      "[1000]\ttraining's l1: 0.236615\tvalid_1's l1: 0.398994\n",
      "[1200]\ttraining's l1: 0.214797\tvalid_1's l1: 0.392847\n",
      "[1400]\ttraining's l1: 0.195999\tvalid_1's l1: 0.387952\n",
      "[1600]\ttraining's l1: 0.180057\tvalid_1's l1: 0.384491\n",
      "[1800]\ttraining's l1: 0.165931\tvalid_1's l1: 0.381248\n",
      "[2000]\ttraining's l1: 0.15373\tvalid_1's l1: 0.378931\n",
      "[2200]\ttraining's l1: 0.14282\tvalid_1's l1: 0.376854\n",
      "[2400]\ttraining's l1: 0.132999\tvalid_1's l1: 0.375303\n",
      "[2600]\ttraining's l1: 0.123989\tvalid_1's l1: 0.373931\n",
      "[2800]\ttraining's l1: 0.116002\tvalid_1's l1: 0.372836\n",
      "[3000]\ttraining's l1: 0.108673\tvalid_1's l1: 0.371864\n",
      "[3200]\ttraining's l1: 0.10186\tvalid_1's l1: 0.370984\n",
      "[3400]\ttraining's l1: 0.0956276\tvalid_1's l1: 0.370313\n",
      "[3600]\ttraining's l1: 0.089974\tvalid_1's l1: 0.369517\n",
      "[3800]\ttraining's l1: 0.0846661\tvalid_1's l1: 0.368877\n",
      "[4000]\ttraining's l1: 0.0798938\tvalid_1's l1: 0.368367\n",
      "[4200]\ttraining's l1: 0.075473\tvalid_1's l1: 0.367835\n",
      "[4400]\ttraining's l1: 0.0713375\tvalid_1's l1: 0.367429\n",
      "[4600]\ttraining's l1: 0.067493\tvalid_1's l1: 0.366984\n",
      "[4800]\ttraining's l1: 0.0639315\tvalid_1's l1: 0.366679\n",
      "[5000]\ttraining's l1: 0.0605866\tvalid_1's l1: 0.366395\n",
      "[5200]\ttraining's l1: 0.0574352\tvalid_1's l1: 0.366171\n",
      "[5400]\ttraining's l1: 0.0544854\tvalid_1's l1: 0.36594\n",
      "[5600]\ttraining's l1: 0.0516853\tvalid_1's l1: 0.365703\n",
      "[5800]\ttraining's l1: 0.0490898\tvalid_1's l1: 0.365483\n",
      "[6000]\ttraining's l1: 0.0466527\tvalid_1's l1: 0.36532\n",
      "[6200]\ttraining's l1: 0.0443685\tvalid_1's l1: 0.365186\n",
      "[6400]\ttraining's l1: 0.0422763\tvalid_1's l1: 0.365044\n",
      "[6600]\ttraining's l1: 0.0402643\tvalid_1's l1: 0.364903\n",
      "[6800]\ttraining's l1: 0.0383625\tvalid_1's l1: 0.364805\n",
      "[7000]\ttraining's l1: 0.0365292\tvalid_1's l1: 0.364726\n",
      "[7200]\ttraining's l1: 0.0348165\tvalid_1's l1: 0.364653\n",
      "[7400]\ttraining's l1: 0.0332163\tvalid_1's l1: 0.364556\n",
      "[7600]\ttraining's l1: 0.031698\tvalid_1's l1: 0.364499\n",
      "[7800]\ttraining's l1: 0.0302517\tvalid_1's l1: 0.364435\n",
      "[8000]\ttraining's l1: 0.0288795\tvalid_1's l1: 0.364364\n",
      "[8200]\ttraining's l1: 0.0276048\tvalid_1's l1: 0.364302\n",
      "[8400]\ttraining's l1: 0.0263792\tvalid_1's l1: 0.364269\n",
      "[8600]\ttraining's l1: 0.02523\tvalid_1's l1: 0.364239\n",
      "[8800]\ttraining's l1: 0.024151\tvalid_1's l1: 0.36421\n",
      "[9000]\ttraining's l1: 0.0230956\tvalid_1's l1: 0.364158\n",
      "[9200]\ttraining's l1: 0.0221018\tvalid_1's l1: 0.364123\n",
      "[9400]\ttraining's l1: 0.021164\tvalid_1's l1: 0.36408\n",
      "[9600]\ttraining's l1: 0.0202945\tvalid_1's l1: 0.36405\n",
      "[9800]\ttraining's l1: 0.0194567\tvalid_1's l1: 0.364034\n",
      "[10000]\ttraining's l1: 0.0186603\tvalid_1's l1: 0.364025\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.0186603\tvalid_1's l1: 0.364025\n",
      "fold n°5\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l1: 0.42819\tvalid_1's l1: 0.484132\n",
      "[400]\ttraining's l1: 0.348618\tvalid_1's l1: 0.439949\n",
      "[600]\ttraining's l1: 0.299973\tvalid_1's l1: 0.418758\n",
      "[800]\ttraining's l1: 0.265091\tvalid_1's l1: 0.405728\n",
      "[1000]\ttraining's l1: 0.238087\tvalid_1's l1: 0.396905\n",
      "[1200]\ttraining's l1: 0.215749\tvalid_1's l1: 0.390401\n",
      "[1400]\ttraining's l1: 0.196751\tvalid_1's l1: 0.385393\n",
      "[1600]\ttraining's l1: 0.180698\tvalid_1's l1: 0.381663\n",
      "[1800]\ttraining's l1: 0.166633\tvalid_1's l1: 0.378662\n",
      "[2000]\ttraining's l1: 0.15448\tvalid_1's l1: 0.376102\n",
      "[2200]\ttraining's l1: 0.14353\tvalid_1's l1: 0.37416\n",
      "[2400]\ttraining's l1: 0.133566\tvalid_1's l1: 0.372505\n",
      "[2600]\ttraining's l1: 0.124551\tvalid_1's l1: 0.371027\n",
      "[2800]\ttraining's l1: 0.116442\tvalid_1's l1: 0.36982\n",
      "[3000]\ttraining's l1: 0.10906\tvalid_1's l1: 0.368796\n",
      "[3200]\ttraining's l1: 0.102275\tvalid_1's l1: 0.3679\n",
      "[3400]\ttraining's l1: 0.0961751\tvalid_1's l1: 0.367154\n",
      "[3600]\ttraining's l1: 0.0904708\tvalid_1's l1: 0.366375\n",
      "[3800]\ttraining's l1: 0.0852729\tvalid_1's l1: 0.365824\n",
      "[4000]\ttraining's l1: 0.0804213\tvalid_1's l1: 0.365303\n",
      "[4200]\ttraining's l1: 0.0758982\tvalid_1's l1: 0.364797\n",
      "[4400]\ttraining's l1: 0.0717075\tvalid_1's l1: 0.364328\n",
      "[4600]\ttraining's l1: 0.0678432\tvalid_1's l1: 0.36397\n",
      "[4800]\ttraining's l1: 0.0642442\tvalid_1's l1: 0.363631\n",
      "[5000]\ttraining's l1: 0.0609432\tvalid_1's l1: 0.363307\n",
      "[5200]\ttraining's l1: 0.0578061\tvalid_1's l1: 0.363095\n",
      "[5400]\ttraining's l1: 0.054771\tvalid_1's l1: 0.362819\n",
      "[5600]\ttraining's l1: 0.0519881\tvalid_1's l1: 0.362632\n",
      "[5800]\ttraining's l1: 0.0493963\tvalid_1's l1: 0.362477\n",
      "[6000]\ttraining's l1: 0.0469622\tvalid_1's l1: 0.362328\n",
      "[6200]\ttraining's l1: 0.044654\tvalid_1's l1: 0.362187\n",
      "[6400]\ttraining's l1: 0.042523\tvalid_1's l1: 0.36203\n",
      "[6600]\ttraining's l1: 0.0405107\tvalid_1's l1: 0.361896\n",
      "[6800]\ttraining's l1: 0.0385714\tvalid_1's l1: 0.361766\n",
      "[7000]\ttraining's l1: 0.0367345\tvalid_1's l1: 0.361665\n",
      "[7200]\ttraining's l1: 0.0349913\tvalid_1's l1: 0.361556\n",
      "[7400]\ttraining's l1: 0.0333881\tvalid_1's l1: 0.361464\n",
      "[7600]\ttraining's l1: 0.0318703\tvalid_1's l1: 0.361399\n",
      "[7800]\ttraining's l1: 0.0304113\tvalid_1's l1: 0.361336\n",
      "[8000]\ttraining's l1: 0.0290425\tvalid_1's l1: 0.361286\n",
      "[8200]\ttraining's l1: 0.0277424\tvalid_1's l1: 0.361243\n",
      "[8400]\ttraining's l1: 0.0265082\tvalid_1's l1: 0.361183\n",
      "[8600]\ttraining's l1: 0.0253469\tvalid_1's l1: 0.361138\n",
      "[8800]\ttraining's l1: 0.0242391\tvalid_1's l1: 0.361085\n",
      "[9000]\ttraining's l1: 0.0231869\tvalid_1's l1: 0.361043\n",
      "[9200]\ttraining's l1: 0.0221695\tvalid_1's l1: 0.360997\n",
      "[9400]\ttraining's l1: 0.0212404\tvalid_1's l1: 0.360948\n",
      "[9600]\ttraining's l1: 0.0203419\tvalid_1's l1: 0.360907\n",
      "[9800]\ttraining's l1: 0.0194945\tvalid_1's l1: 0.360881\n",
      "[10000]\ttraining's l1: 0.0187006\tvalid_1's l1: 0.360848\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.0187006\tvalid_1's l1: 0.360848\n",
      "~~~~~~~~~ type name: 3JHC  ~~~~~~~~~\n",
      "validation method: GroupKFold(n_splits=5) groups value: molecule_name\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l1: 0.922269\tvalid_1's l1: 0.980949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[400]\ttraining's l1: 0.805145\tvalid_1's l1: 0.903094\n",
      "[600]\ttraining's l1: 0.726429\tvalid_1's l1: 0.856749\n",
      "[800]\ttraining's l1: 0.668457\tvalid_1's l1: 0.827059\n",
      "[1000]\ttraining's l1: 0.621582\tvalid_1's l1: 0.805677\n",
      "[1200]\ttraining's l1: 0.581669\tvalid_1's l1: 0.788311\n",
      "[1400]\ttraining's l1: 0.547831\tvalid_1's l1: 0.775674\n",
      "[1600]\ttraining's l1: 0.518604\tvalid_1's l1: 0.76534\n",
      "[1800]\ttraining's l1: 0.491598\tvalid_1's l1: 0.756177\n",
      "[2000]\ttraining's l1: 0.467194\tvalid_1's l1: 0.748481\n",
      "[2200]\ttraining's l1: 0.444721\tvalid_1's l1: 0.741204\n",
      "[2400]\ttraining's l1: 0.424333\tvalid_1's l1: 0.735524\n",
      "[2600]\ttraining's l1: 0.405496\tvalid_1's l1: 0.730373\n",
      "[2800]\ttraining's l1: 0.388293\tvalid_1's l1: 0.725975\n",
      "[3000]\ttraining's l1: 0.371804\tvalid_1's l1: 0.721611\n",
      "[3200]\ttraining's l1: 0.356721\tvalid_1's l1: 0.718073\n",
      "[3400]\ttraining's l1: 0.342505\tvalid_1's l1: 0.714855\n",
      "[3600]\ttraining's l1: 0.329099\tvalid_1's l1: 0.711805\n",
      "[3800]\ttraining's l1: 0.316522\tvalid_1's l1: 0.709027\n",
      "[4000]\ttraining's l1: 0.304743\tvalid_1's l1: 0.706574\n",
      "[4200]\ttraining's l1: 0.293354\tvalid_1's l1: 0.704371\n",
      "[4400]\ttraining's l1: 0.282583\tvalid_1's l1: 0.702115\n",
      "[4600]\ttraining's l1: 0.272307\tvalid_1's l1: 0.700331\n",
      "[4800]\ttraining's l1: 0.262744\tvalid_1's l1: 0.6986\n",
      "[5000]\ttraining's l1: 0.253436\tvalid_1's l1: 0.696932\n",
      "[5200]\ttraining's l1: 0.244681\tvalid_1's l1: 0.695383\n",
      "[5400]\ttraining's l1: 0.236297\tvalid_1's l1: 0.693953\n",
      "[5600]\ttraining's l1: 0.228282\tvalid_1's l1: 0.692789\n",
      "[5800]\ttraining's l1: 0.220581\tvalid_1's l1: 0.691429\n",
      "[6000]\ttraining's l1: 0.213247\tvalid_1's l1: 0.690249\n",
      "[6200]\ttraining's l1: 0.206342\tvalid_1's l1: 0.689258\n",
      "[6400]\ttraining's l1: 0.199695\tvalid_1's l1: 0.688395\n",
      "[6600]\ttraining's l1: 0.19338\tvalid_1's l1: 0.687399\n",
      "[6800]\ttraining's l1: 0.187249\tvalid_1's l1: 0.686506\n",
      "[7000]\ttraining's l1: 0.181315\tvalid_1's l1: 0.685707\n",
      "[7200]\ttraining's l1: 0.175754\tvalid_1's l1: 0.684927\n",
      "[7400]\ttraining's l1: 0.170347\tvalid_1's l1: 0.684183\n",
      "[7600]\ttraining's l1: 0.165183\tvalid_1's l1: 0.683411\n",
      "[7800]\ttraining's l1: 0.160096\tvalid_1's l1: 0.682659\n",
      "[8000]\ttraining's l1: 0.155304\tvalid_1's l1: 0.681987\n",
      "[8200]\ttraining's l1: 0.150628\tvalid_1's l1: 0.681399\n",
      "[8400]\ttraining's l1: 0.146158\tvalid_1's l1: 0.680782\n",
      "[8600]\ttraining's l1: 0.141797\tvalid_1's l1: 0.680244\n",
      "[8800]\ttraining's l1: 0.137566\tvalid_1's l1: 0.679724\n",
      "[9000]\ttraining's l1: 0.133615\tvalid_1's l1: 0.679219\n",
      "[9200]\ttraining's l1: 0.129753\tvalid_1's l1: 0.67884\n",
      "[9400]\ttraining's l1: 0.12606\tvalid_1's l1: 0.678394\n",
      "[9600]\ttraining's l1: 0.122483\tvalid_1's l1: 0.67788\n",
      "[9800]\ttraining's l1: 0.118949\tvalid_1's l1: 0.677505\n",
      "[10000]\ttraining's l1: 0.115597\tvalid_1's l1: 0.677083\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.115597\tvalid_1's l1: 0.677083\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l1: 0.924577\tvalid_1's l1: 0.982611\n",
      "[400]\ttraining's l1: 0.804951\tvalid_1's l1: 0.902929\n",
      "[600]\ttraining's l1: 0.727406\tvalid_1's l1: 0.858359\n",
      "[800]\ttraining's l1: 0.667018\tvalid_1's l1: 0.826894\n",
      "[1000]\ttraining's l1: 0.620682\tvalid_1's l1: 0.80572\n",
      "[1200]\ttraining's l1: 0.581807\tvalid_1's l1: 0.789823\n",
      "[1400]\ttraining's l1: 0.547211\tvalid_1's l1: 0.776027\n",
      "[1600]\ttraining's l1: 0.517141\tvalid_1's l1: 0.76544\n",
      "[1800]\ttraining's l1: 0.490086\tvalid_1's l1: 0.756468\n",
      "[2000]\ttraining's l1: 0.465472\tvalid_1's l1: 0.74816\n",
      "[2200]\ttraining's l1: 0.443385\tvalid_1's l1: 0.741686\n",
      "[2400]\ttraining's l1: 0.42365\tvalid_1's l1: 0.736364\n",
      "[2600]\ttraining's l1: 0.404395\tvalid_1's l1: 0.730964\n",
      "[2800]\ttraining's l1: 0.386987\tvalid_1's l1: 0.726326\n",
      "[3000]\ttraining's l1: 0.370912\tvalid_1's l1: 0.722408\n",
      "[3200]\ttraining's l1: 0.356\tvalid_1's l1: 0.718898\n",
      "[3400]\ttraining's l1: 0.34188\tvalid_1's l1: 0.715604\n",
      "[3600]\ttraining's l1: 0.328336\tvalid_1's l1: 0.712535\n",
      "[3800]\ttraining's l1: 0.315974\tvalid_1's l1: 0.709958\n",
      "[4000]\ttraining's l1: 0.304036\tvalid_1's l1: 0.707408\n",
      "[4200]\ttraining's l1: 0.292623\tvalid_1's l1: 0.704958\n",
      "[4400]\ttraining's l1: 0.281976\tvalid_1's l1: 0.703057\n",
      "[4600]\ttraining's l1: 0.271942\tvalid_1's l1: 0.701292\n",
      "[4800]\ttraining's l1: 0.262203\tvalid_1's l1: 0.69943\n",
      "[5000]\ttraining's l1: 0.253097\tvalid_1's l1: 0.69783\n",
      "[5200]\ttraining's l1: 0.244308\tvalid_1's l1: 0.696246\n",
      "[5400]\ttraining's l1: 0.235966\tvalid_1's l1: 0.694811\n",
      "[5600]\ttraining's l1: 0.228014\tvalid_1's l1: 0.693473\n",
      "[5800]\ttraining's l1: 0.220473\tvalid_1's l1: 0.692199\n",
      "[6000]\ttraining's l1: 0.213067\tvalid_1's l1: 0.691016\n",
      "[6200]\ttraining's l1: 0.206215\tvalid_1's l1: 0.690009\n",
      "[6400]\ttraining's l1: 0.199483\tvalid_1's l1: 0.688895\n",
      "[6600]\ttraining's l1: 0.193139\tvalid_1's l1: 0.688014\n",
      "[6800]\ttraining's l1: 0.187026\tvalid_1's l1: 0.687134\n",
      "[7000]\ttraining's l1: 0.1811\tvalid_1's l1: 0.686379\n",
      "[7200]\ttraining's l1: 0.175468\tvalid_1's l1: 0.685543\n",
      "[7400]\ttraining's l1: 0.170143\tvalid_1's l1: 0.684719\n",
      "[7600]\ttraining's l1: 0.164953\tvalid_1's l1: 0.684102\n",
      "[7800]\ttraining's l1: 0.159862\tvalid_1's l1: 0.683421\n",
      "[8000]\ttraining's l1: 0.15503\tvalid_1's l1: 0.6828\n",
      "[8200]\ttraining's l1: 0.15031\tvalid_1's l1: 0.682224\n",
      "[8400]\ttraining's l1: 0.145829\tvalid_1's l1: 0.681608\n",
      "[8600]\ttraining's l1: 0.141515\tvalid_1's l1: 0.681076\n",
      "[8800]\ttraining's l1: 0.137327\tvalid_1's l1: 0.68062\n",
      "[9000]\ttraining's l1: 0.133285\tvalid_1's l1: 0.680095\n",
      "[9200]\ttraining's l1: 0.129365\tvalid_1's l1: 0.67964\n",
      "[9400]\ttraining's l1: 0.125667\tvalid_1's l1: 0.67915\n",
      "[9600]\ttraining's l1: 0.122043\tvalid_1's l1: 0.67877\n",
      "[9800]\ttraining's l1: 0.118563\tvalid_1's l1: 0.67836\n",
      "[10000]\ttraining's l1: 0.115143\tvalid_1's l1: 0.67795\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.115143\tvalid_1's l1: 0.67795\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l1: 0.925025\tvalid_1's l1: 0.981066\n",
      "[400]\ttraining's l1: 0.803324\tvalid_1's l1: 0.897696\n",
      "[600]\ttraining's l1: 0.726246\tvalid_1's l1: 0.853596\n",
      "[800]\ttraining's l1: 0.668134\tvalid_1's l1: 0.823895\n",
      "[1000]\ttraining's l1: 0.620814\tvalid_1's l1: 0.802006\n",
      "[1200]\ttraining's l1: 0.58184\tvalid_1's l1: 0.78579\n",
      "[1400]\ttraining's l1: 0.547968\tvalid_1's l1: 0.773168\n",
      "[1600]\ttraining's l1: 0.517751\tvalid_1's l1: 0.762274\n",
      "[1800]\ttraining's l1: 0.491223\tvalid_1's l1: 0.753901\n",
      "[2000]\ttraining's l1: 0.467061\tvalid_1's l1: 0.746317\n",
      "[2200]\ttraining's l1: 0.4448\tvalid_1's l1: 0.740028\n",
      "[2400]\ttraining's l1: 0.424562\tvalid_1's l1: 0.734538\n",
      "[2600]\ttraining's l1: 0.406213\tvalid_1's l1: 0.729946\n",
      "[2800]\ttraining's l1: 0.388775\tvalid_1's l1: 0.725106\n",
      "[3000]\ttraining's l1: 0.372358\tvalid_1's l1: 0.720955\n",
      "[3200]\ttraining's l1: 0.356922\tvalid_1's l1: 0.717231\n",
      "[3400]\ttraining's l1: 0.342702\tvalid_1's l1: 0.713904\n",
      "[3600]\ttraining's l1: 0.329163\tvalid_1's l1: 0.710779\n",
      "[3800]\ttraining's l1: 0.316405\tvalid_1's l1: 0.707999\n",
      "[4000]\ttraining's l1: 0.304332\tvalid_1's l1: 0.705301\n",
      "[4200]\ttraining's l1: 0.292937\tvalid_1's l1: 0.703095\n",
      "[4400]\ttraining's l1: 0.282109\tvalid_1's l1: 0.700984\n",
      "[4600]\ttraining's l1: 0.272022\tvalid_1's l1: 0.699037\n",
      "[4800]\ttraining's l1: 0.262303\tvalid_1's l1: 0.697431\n",
      "[5000]\ttraining's l1: 0.253144\tvalid_1's l1: 0.695742\n",
      "[5200]\ttraining's l1: 0.244325\tvalid_1's l1: 0.694103\n",
      "[5400]\ttraining's l1: 0.235959\tvalid_1's l1: 0.692759\n",
      "[5600]\ttraining's l1: 0.227832\tvalid_1's l1: 0.691414\n",
      "[5800]\ttraining's l1: 0.219991\tvalid_1's l1: 0.689954\n",
      "[6000]\ttraining's l1: 0.21279\tvalid_1's l1: 0.688676\n",
      "[6200]\ttraining's l1: 0.205919\tvalid_1's l1: 0.687559\n",
      "[6400]\ttraining's l1: 0.199257\tvalid_1's l1: 0.686522\n",
      "[6600]\ttraining's l1: 0.192799\tvalid_1's l1: 0.6855\n",
      "[6800]\ttraining's l1: 0.186671\tvalid_1's l1: 0.684656\n",
      "[7000]\ttraining's l1: 0.180807\tvalid_1's l1: 0.683874\n",
      "[7200]\ttraining's l1: 0.175128\tvalid_1's l1: 0.68302\n",
      "[7400]\ttraining's l1: 0.169727\tvalid_1's l1: 0.682241\n",
      "[7600]\ttraining's l1: 0.164491\tvalid_1's l1: 0.681468\n",
      "[7800]\ttraining's l1: 0.159511\tvalid_1's l1: 0.680731\n",
      "[8000]\ttraining's l1: 0.154664\tvalid_1's l1: 0.680186\n",
      "[8200]\ttraining's l1: 0.150095\tvalid_1's l1: 0.679607\n",
      "[8400]\ttraining's l1: 0.145638\tvalid_1's l1: 0.679093\n",
      "[8600]\ttraining's l1: 0.141334\tvalid_1's l1: 0.678546\n",
      "[8800]\ttraining's l1: 0.137128\tvalid_1's l1: 0.678018\n",
      "[9000]\ttraining's l1: 0.133157\tvalid_1's l1: 0.677557\n",
      "[9200]\ttraining's l1: 0.129298\tvalid_1's l1: 0.677134\n",
      "[9400]\ttraining's l1: 0.125534\tvalid_1's l1: 0.67669\n",
      "[9600]\ttraining's l1: 0.121929\tvalid_1's l1: 0.676254\n",
      "[9800]\ttraining's l1: 0.118539\tvalid_1's l1: 0.67586\n",
      "[10000]\ttraining's l1: 0.115181\tvalid_1's l1: 0.675473\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.115181\tvalid_1's l1: 0.675473\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l1: 0.922384\tvalid_1's l1: 0.982025\n",
      "[400]\ttraining's l1: 0.803264\tvalid_1's l1: 0.90198\n",
      "[600]\ttraining's l1: 0.723538\tvalid_1's l1: 0.854785\n",
      "[800]\ttraining's l1: 0.666101\tvalid_1's l1: 0.82492\n",
      "[1000]\ttraining's l1: 0.619032\tvalid_1's l1: 0.803091\n",
      "[1200]\ttraining's l1: 0.580225\tvalid_1's l1: 0.787011\n",
      "[1400]\ttraining's l1: 0.546078\tvalid_1's l1: 0.773638\n",
      "[1600]\ttraining's l1: 0.516531\tvalid_1's l1: 0.763391\n",
      "[1800]\ttraining's l1: 0.489208\tvalid_1's l1: 0.754018\n",
      "[2000]\ttraining's l1: 0.465008\tvalid_1's l1: 0.746318\n",
      "[2200]\ttraining's l1: 0.442744\tvalid_1's l1: 0.739903\n",
      "[2400]\ttraining's l1: 0.422795\tvalid_1's l1: 0.734491\n",
      "[2600]\ttraining's l1: 0.404127\tvalid_1's l1: 0.729672\n",
      "[2800]\ttraining's l1: 0.386688\tvalid_1's l1: 0.724974\n",
      "[3000]\ttraining's l1: 0.370691\tvalid_1's l1: 0.721059\n",
      "[3200]\ttraining's l1: 0.35555\tvalid_1's l1: 0.717607\n",
      "[3400]\ttraining's l1: 0.341358\tvalid_1's l1: 0.714157\n",
      "[3600]\ttraining's l1: 0.328027\tvalid_1's l1: 0.711274\n",
      "[3800]\ttraining's l1: 0.315556\tvalid_1's l1: 0.708703\n",
      "[4000]\ttraining's l1: 0.303409\tvalid_1's l1: 0.705973\n",
      "[4200]\ttraining's l1: 0.292278\tvalid_1's l1: 0.703891\n",
      "[4400]\ttraining's l1: 0.281521\tvalid_1's l1: 0.701871\n",
      "[4600]\ttraining's l1: 0.271439\tvalid_1's l1: 0.700111\n",
      "[4800]\ttraining's l1: 0.261815\tvalid_1's l1: 0.698375\n",
      "[5000]\ttraining's l1: 0.252511\tvalid_1's l1: 0.696693\n",
      "[5200]\ttraining's l1: 0.243847\tvalid_1's l1: 0.695109\n",
      "[5400]\ttraining's l1: 0.235656\tvalid_1's l1: 0.6937\n",
      "[5600]\ttraining's l1: 0.227728\tvalid_1's l1: 0.692323\n",
      "[5800]\ttraining's l1: 0.220153\tvalid_1's l1: 0.691049\n",
      "[6000]\ttraining's l1: 0.212946\tvalid_1's l1: 0.689952\n",
      "[6200]\ttraining's l1: 0.205902\tvalid_1's l1: 0.688954\n",
      "[6400]\ttraining's l1: 0.199272\tvalid_1's l1: 0.688018\n",
      "[6600]\ttraining's l1: 0.193004\tvalid_1's l1: 0.686983\n",
      "[6800]\ttraining's l1: 0.186798\tvalid_1's l1: 0.686067\n",
      "[7000]\ttraining's l1: 0.180868\tvalid_1's l1: 0.685184\n",
      "[7200]\ttraining's l1: 0.175279\tvalid_1's l1: 0.684385\n",
      "[7400]\ttraining's l1: 0.169837\tvalid_1's l1: 0.683572\n",
      "[7600]\ttraining's l1: 0.164648\tvalid_1's l1: 0.682842\n",
      "[7800]\ttraining's l1: 0.15961\tvalid_1's l1: 0.682131\n",
      "[8000]\ttraining's l1: 0.154807\tvalid_1's l1: 0.68148\n",
      "[8200]\ttraining's l1: 0.150114\tvalid_1's l1: 0.680929\n",
      "[8400]\ttraining's l1: 0.145594\tvalid_1's l1: 0.680396\n",
      "[8600]\ttraining's l1: 0.141294\tvalid_1's l1: 0.679909\n",
      "[8800]\ttraining's l1: 0.137162\tvalid_1's l1: 0.679388\n",
      "[9000]\ttraining's l1: 0.133154\tvalid_1's l1: 0.678879\n",
      "[9200]\ttraining's l1: 0.12924\tvalid_1's l1: 0.678454\n",
      "[9400]\ttraining's l1: 0.125505\tvalid_1's l1: 0.678041\n",
      "[9600]\ttraining's l1: 0.121873\tvalid_1's l1: 0.677611\n",
      "[9800]\ttraining's l1: 0.118401\tvalid_1's l1: 0.67719\n",
      "[10000]\ttraining's l1: 0.115034\tvalid_1's l1: 0.676802\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.115034\tvalid_1's l1: 0.676802\n",
      "fold n°5\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l1: 0.923051\tvalid_1's l1: 0.977142\n",
      "[400]\ttraining's l1: 0.802521\tvalid_1's l1: 0.895462\n",
      "[600]\ttraining's l1: 0.725311\tvalid_1's l1: 0.851487\n",
      "[800]\ttraining's l1: 0.668338\tvalid_1's l1: 0.823455\n",
      "[1000]\ttraining's l1: 0.621572\tvalid_1's l1: 0.801642\n",
      "[1200]\ttraining's l1: 0.581164\tvalid_1's l1: 0.784366\n",
      "[1400]\ttraining's l1: 0.548425\tvalid_1's l1: 0.772656\n",
      "[1600]\ttraining's l1: 0.518761\tvalid_1's l1: 0.762112\n",
      "[1800]\ttraining's l1: 0.491416\tvalid_1's l1: 0.753189\n",
      "[2000]\ttraining's l1: 0.466421\tvalid_1's l1: 0.745072\n",
      "[2200]\ttraining's l1: 0.444319\tvalid_1's l1: 0.73865\n",
      "[2400]\ttraining's l1: 0.423815\tvalid_1's l1: 0.733003\n",
      "[2600]\ttraining's l1: 0.405014\tvalid_1's l1: 0.728153\n",
      "[2800]\ttraining's l1: 0.387412\tvalid_1's l1: 0.723588\n",
      "[3000]\ttraining's l1: 0.37114\tvalid_1's l1: 0.719425\n",
      "[3200]\ttraining's l1: 0.356082\tvalid_1's l1: 0.716016\n",
      "[3400]\ttraining's l1: 0.342072\tvalid_1's l1: 0.712811\n",
      "[3600]\ttraining's l1: 0.328656\tvalid_1's l1: 0.7097\n",
      "[3800]\ttraining's l1: 0.315953\tvalid_1's l1: 0.706874\n",
      "[4000]\ttraining's l1: 0.303907\tvalid_1's l1: 0.704358\n",
      "[4200]\ttraining's l1: 0.292558\tvalid_1's l1: 0.702097\n",
      "[4400]\ttraining's l1: 0.28183\tvalid_1's l1: 0.70019\n",
      "[4600]\ttraining's l1: 0.271619\tvalid_1's l1: 0.698321\n",
      "[4800]\ttraining's l1: 0.262088\tvalid_1's l1: 0.696693\n",
      "[5000]\ttraining's l1: 0.25289\tvalid_1's l1: 0.695024\n",
      "[5200]\ttraining's l1: 0.244123\tvalid_1's l1: 0.693581\n",
      "[5400]\ttraining's l1: 0.235821\tvalid_1's l1: 0.69215\n",
      "[5600]\ttraining's l1: 0.227887\tvalid_1's l1: 0.690884\n",
      "[5800]\ttraining's l1: 0.220373\tvalid_1's l1: 0.689568\n",
      "[6000]\ttraining's l1: 0.212913\tvalid_1's l1: 0.688325\n",
      "[6200]\ttraining's l1: 0.206026\tvalid_1's l1: 0.687333\n",
      "[6400]\ttraining's l1: 0.199392\tvalid_1's l1: 0.686328\n",
      "[6600]\ttraining's l1: 0.192987\tvalid_1's l1: 0.685359\n",
      "[6800]\ttraining's l1: 0.186884\tvalid_1's l1: 0.684402\n",
      "[7000]\ttraining's l1: 0.180937\tvalid_1's l1: 0.683674\n",
      "[7200]\ttraining's l1: 0.175352\tvalid_1's l1: 0.682803\n",
      "[7400]\ttraining's l1: 0.169933\tvalid_1's l1: 0.681988\n",
      "[7600]\ttraining's l1: 0.164766\tvalid_1's l1: 0.681385\n",
      "[7800]\ttraining's l1: 0.159764\tvalid_1's l1: 0.680706\n",
      "[8000]\ttraining's l1: 0.154932\tvalid_1's l1: 0.680154\n",
      "[8200]\ttraining's l1: 0.15024\tvalid_1's l1: 0.679632\n",
      "[8400]\ttraining's l1: 0.145782\tvalid_1's l1: 0.67912\n",
      "[8600]\ttraining's l1: 0.141466\tvalid_1's l1: 0.678567\n",
      "[8800]\ttraining's l1: 0.137282\tvalid_1's l1: 0.67812\n",
      "[9000]\ttraining's l1: 0.133286\tvalid_1's l1: 0.677627\n",
      "[9200]\ttraining's l1: 0.129423\tvalid_1's l1: 0.677208\n",
      "[9400]\ttraining's l1: 0.125675\tvalid_1's l1: 0.676748\n",
      "[9600]\ttraining's l1: 0.122084\tvalid_1's l1: 0.676313\n",
      "[9800]\ttraining's l1: 0.118583\tvalid_1's l1: 0.675876\n",
      "[10000]\ttraining's l1: 0.115162\tvalid_1's l1: 0.675509\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.115162\tvalid_1's l1: 0.675509\n",
      "~~~~~~~~~ type name: 3JHN  ~~~~~~~~~\n",
      "validation method: GroupKFold(n_splits=5) groups value: molecule_name\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l1: 0.181383\tvalid_1's l1: 0.278945\n",
      "[400]\ttraining's l1: 0.123776\tvalid_1's l1: 0.26161\n",
      "[600]\ttraining's l1: 0.0905188\tvalid_1's l1: 0.254127\n",
      "[800]\ttraining's l1: 0.0688015\tvalid_1's l1: 0.250142\n",
      "[1000]\ttraining's l1: 0.0537182\tvalid_1's l1: 0.247824\n",
      "[1200]\ttraining's l1: 0.0426822\tvalid_1's l1: 0.246253\n",
      "[1400]\ttraining's l1: 0.0342686\tvalid_1's l1: 0.2452\n",
      "[1600]\ttraining's l1: 0.027761\tvalid_1's l1: 0.244501\n",
      "[1800]\ttraining's l1: 0.0227378\tvalid_1's l1: 0.243993\n",
      "[2000]\ttraining's l1: 0.0187837\tvalid_1's l1: 0.243593\n",
      "[2200]\ttraining's l1: 0.01564\tvalid_1's l1: 0.243336\n",
      "[2400]\ttraining's l1: 0.0130582\tvalid_1's l1: 0.243127\n",
      "[2600]\ttraining's l1: 0.0109875\tvalid_1's l1: 0.242986\n",
      "[2800]\ttraining's l1: 0.00927327\tvalid_1's l1: 0.242839\n",
      "[3000]\ttraining's l1: 0.007862\tvalid_1's l1: 0.242775\n",
      "[3200]\ttraining's l1: 0.00670234\tvalid_1's l1: 0.242726\n",
      "[3400]\ttraining's l1: 0.00573343\tvalid_1's l1: 0.242663\n",
      "[3600]\ttraining's l1: 0.00493092\tvalid_1's l1: 0.242622\n",
      "[3800]\ttraining's l1: 0.00424026\tvalid_1's l1: 0.242583\n",
      "[4000]\ttraining's l1: 0.00366416\tvalid_1's l1: 0.24257\n",
      "[4200]\ttraining's l1: 0.0031847\tvalid_1's l1: 0.242552\n",
      "[4400]\ttraining's l1: 0.00276148\tvalid_1's l1: 0.242538\n",
      "[4600]\ttraining's l1: 0.00240934\tvalid_1's l1: 0.242523\n",
      "[4800]\ttraining's l1: 0.00210569\tvalid_1's l1: 0.242515\n",
      "[5000]\ttraining's l1: 0.00184593\tvalid_1's l1: 0.242507\n",
      "[5200]\ttraining's l1: 0.00162526\tvalid_1's l1: 0.242498\n",
      "[5400]\ttraining's l1: 0.00143123\tvalid_1's l1: 0.242494\n",
      "[5600]\ttraining's l1: 0.00125828\tvalid_1's l1: 0.24249\n",
      "[5800]\ttraining's l1: 0.00111036\tvalid_1's l1: 0.242487\n",
      "[6000]\ttraining's l1: 0.000983461\tvalid_1's l1: 0.242486\n",
      "[6200]\ttraining's l1: 0.000873836\tvalid_1's l1: 0.242482\n",
      "[6400]\ttraining's l1: 0.000775928\tvalid_1's l1: 0.242481\n",
      "[6600]\ttraining's l1: 0.000692832\tvalid_1's l1: 0.242478\n",
      "[6800]\ttraining's l1: 0.000618538\tvalid_1's l1: 0.242477\n",
      "[7000]\ttraining's l1: 0.00055279\tvalid_1's l1: 0.242475\n",
      "[7200]\ttraining's l1: 0.000494259\tvalid_1's l1: 0.242474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7400]\ttraining's l1: 0.000443948\tvalid_1's l1: 0.242472\n",
      "Early stopping, best iteration is:\n",
      "[7336]\ttraining's l1: 0.000459255\tvalid_1's l1: 0.242472\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l1: 0.181621\tvalid_1's l1: 0.275036\n",
      "[400]\ttraining's l1: 0.123853\tvalid_1's l1: 0.257661\n",
      "[600]\ttraining's l1: 0.0907254\tvalid_1's l1: 0.250953\n",
      "[800]\ttraining's l1: 0.0690901\tvalid_1's l1: 0.246901\n",
      "[1000]\ttraining's l1: 0.0539084\tvalid_1's l1: 0.244128\n",
      "[1200]\ttraining's l1: 0.0427186\tvalid_1's l1: 0.242601\n",
      "[1400]\ttraining's l1: 0.0343062\tvalid_1's l1: 0.241428\n",
      "[1600]\ttraining's l1: 0.027839\tvalid_1's l1: 0.240795\n",
      "[1800]\ttraining's l1: 0.022827\tvalid_1's l1: 0.240331\n",
      "[2000]\ttraining's l1: 0.0189044\tvalid_1's l1: 0.239975\n",
      "[2200]\ttraining's l1: 0.0156573\tvalid_1's l1: 0.239701\n",
      "[2400]\ttraining's l1: 0.0130729\tvalid_1's l1: 0.239541\n",
      "[2600]\ttraining's l1: 0.0109879\tvalid_1's l1: 0.239379\n",
      "[2800]\ttraining's l1: 0.00928283\tvalid_1's l1: 0.239307\n",
      "[3000]\ttraining's l1: 0.00788177\tvalid_1's l1: 0.239236\n",
      "[3200]\ttraining's l1: 0.00671962\tvalid_1's l1: 0.23917\n",
      "[3400]\ttraining's l1: 0.005757\tvalid_1's l1: 0.23912\n",
      "[3600]\ttraining's l1: 0.00494496\tvalid_1's l1: 0.239059\n",
      "[3800]\ttraining's l1: 0.00424651\tvalid_1's l1: 0.239024\n",
      "[4000]\ttraining's l1: 0.00367465\tvalid_1's l1: 0.238997\n",
      "[4200]\ttraining's l1: 0.00318881\tvalid_1's l1: 0.238968\n",
      "[4400]\ttraining's l1: 0.00276592\tvalid_1's l1: 0.238955\n",
      "[4600]\ttraining's l1: 0.00241191\tvalid_1's l1: 0.238943\n",
      "[4800]\ttraining's l1: 0.00210871\tvalid_1's l1: 0.238933\n",
      "[5000]\ttraining's l1: 0.00184906\tvalid_1's l1: 0.238918\n",
      "[5200]\ttraining's l1: 0.00162856\tvalid_1's l1: 0.238908\n",
      "[5400]\ttraining's l1: 0.00143159\tvalid_1's l1: 0.238899\n",
      "[5600]\ttraining's l1: 0.0012596\tvalid_1's l1: 0.238897\n",
      "[5800]\ttraining's l1: 0.00111232\tvalid_1's l1: 0.238891\n",
      "[6000]\ttraining's l1: 0.000982865\tvalid_1's l1: 0.238886\n",
      "[6200]\ttraining's l1: 0.000870857\tvalid_1's l1: 0.238884\n",
      "[6400]\ttraining's l1: 0.000773316\tvalid_1's l1: 0.238881\n",
      "[6600]\ttraining's l1: 0.000689809\tvalid_1's l1: 0.238878\n",
      "[6800]\ttraining's l1: 0.00061335\tvalid_1's l1: 0.238874\n",
      "[7000]\ttraining's l1: 0.000545502\tvalid_1's l1: 0.238873\n",
      "[7200]\ttraining's l1: 0.000487843\tvalid_1's l1: 0.238872\n",
      "[7400]\ttraining's l1: 0.000437132\tvalid_1's l1: 0.23887\n",
      "[7600]\ttraining's l1: 0.000391902\tvalid_1's l1: 0.238869\n",
      "[7800]\ttraining's l1: 0.000351718\tvalid_1's l1: 0.238868\n",
      "[8000]\ttraining's l1: 0.000316727\tvalid_1's l1: 0.238867\n",
      "[8200]\ttraining's l1: 0.000285072\tvalid_1's l1: 0.238866\n",
      "[8400]\ttraining's l1: 0.000257202\tvalid_1's l1: 0.238865\n",
      "[8600]\ttraining's l1: 0.000232218\tvalid_1's l1: 0.238864\n",
      "Early stopping, best iteration is:\n",
      "[8542]\ttraining's l1: 0.000239193\tvalid_1's l1: 0.238864\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l1: 0.182038\tvalid_1's l1: 0.277181\n",
      "[400]\ttraining's l1: 0.124213\tvalid_1's l1: 0.260801\n",
      "[600]\ttraining's l1: 0.0909534\tvalid_1's l1: 0.253612\n",
      "[800]\ttraining's l1: 0.0691986\tvalid_1's l1: 0.249709\n",
      "[1000]\ttraining's l1: 0.0539086\tvalid_1's l1: 0.247225\n",
      "[1200]\ttraining's l1: 0.0427671\tvalid_1's l1: 0.245691\n",
      "[1400]\ttraining's l1: 0.0343257\tvalid_1's l1: 0.244763\n",
      "[1600]\ttraining's l1: 0.0278478\tvalid_1's l1: 0.244051\n",
      "[1800]\ttraining's l1: 0.0227811\tvalid_1's l1: 0.243497\n",
      "[2000]\ttraining's l1: 0.0188011\tvalid_1's l1: 0.24315\n",
      "[2200]\ttraining's l1: 0.0156733\tvalid_1's l1: 0.2429\n",
      "[2400]\ttraining's l1: 0.0130952\tvalid_1's l1: 0.242672\n",
      "[2600]\ttraining's l1: 0.0109997\tvalid_1's l1: 0.242545\n",
      "[2800]\ttraining's l1: 0.00928991\tvalid_1's l1: 0.242428\n",
      "[3000]\ttraining's l1: 0.00788639\tvalid_1's l1: 0.242327\n",
      "[3200]\ttraining's l1: 0.00671652\tvalid_1's l1: 0.242253\n",
      "[3400]\ttraining's l1: 0.00573388\tvalid_1's l1: 0.2422\n",
      "[3600]\ttraining's l1: 0.00492507\tvalid_1's l1: 0.242158\n",
      "[3800]\ttraining's l1: 0.00423693\tvalid_1's l1: 0.242119\n",
      "[4000]\ttraining's l1: 0.00366165\tvalid_1's l1: 0.242103\n",
      "[4200]\ttraining's l1: 0.00318121\tvalid_1's l1: 0.242082\n",
      "[4400]\ttraining's l1: 0.00276707\tvalid_1's l1: 0.242066\n",
      "[4600]\ttraining's l1: 0.00241418\tvalid_1's l1: 0.242058\n",
      "[4800]\ttraining's l1: 0.00211068\tvalid_1's l1: 0.242045\n",
      "[5000]\ttraining's l1: 0.0018518\tvalid_1's l1: 0.24204\n",
      "[5200]\ttraining's l1: 0.0016268\tvalid_1's l1: 0.242029\n",
      "[5400]\ttraining's l1: 0.0014314\tvalid_1's l1: 0.242026\n",
      "[5600]\ttraining's l1: 0.00126298\tvalid_1's l1: 0.24202\n",
      "[5800]\ttraining's l1: 0.00111418\tvalid_1's l1: 0.242016\n",
      "[6000]\ttraining's l1: 0.000988033\tvalid_1's l1: 0.242012\n",
      "[6200]\ttraining's l1: 0.000876925\tvalid_1's l1: 0.242011\n",
      "[6400]\ttraining's l1: 0.000780517\tvalid_1's l1: 0.24201\n",
      "[6600]\ttraining's l1: 0.000695896\tvalid_1's l1: 0.242007\n",
      "[6800]\ttraining's l1: 0.000621389\tvalid_1's l1: 0.242004\n",
      "[7000]\ttraining's l1: 0.000555381\tvalid_1's l1: 0.242004\n",
      "[7200]\ttraining's l1: 0.000498009\tvalid_1's l1: 0.242004\n",
      "[7400]\ttraining's l1: 0.000447385\tvalid_1's l1: 0.242002\n",
      "[7600]\ttraining's l1: 0.000402566\tvalid_1's l1: 0.242002\n",
      "[7800]\ttraining's l1: 0.000363307\tvalid_1's l1: 0.242001\n",
      "[8000]\ttraining's l1: 0.000328157\tvalid_1's l1: 0.242001\n",
      "Early stopping, best iteration is:\n",
      "[7841]\ttraining's l1: 0.000355696\tvalid_1's l1: 0.242001\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l1: 0.182158\tvalid_1's l1: 0.27598\n",
      "[400]\ttraining's l1: 0.12452\tvalid_1's l1: 0.259901\n",
      "[600]\ttraining's l1: 0.0908568\tvalid_1's l1: 0.252451\n",
      "[800]\ttraining's l1: 0.0691223\tvalid_1's l1: 0.248366\n",
      "[1000]\ttraining's l1: 0.0538555\tvalid_1's l1: 0.24606\n",
      "[1200]\ttraining's l1: 0.0426865\tvalid_1's l1: 0.244432\n",
      "[1400]\ttraining's l1: 0.0342721\tvalid_1's l1: 0.243447\n",
      "[1600]\ttraining's l1: 0.0278633\tvalid_1's l1: 0.242818\n",
      "[1800]\ttraining's l1: 0.0227716\tvalid_1's l1: 0.242214\n",
      "[2000]\ttraining's l1: 0.0188446\tvalid_1's l1: 0.241861\n",
      "[2200]\ttraining's l1: 0.0156518\tvalid_1's l1: 0.24156\n",
      "[2400]\ttraining's l1: 0.0130895\tvalid_1's l1: 0.24138\n",
      "[2600]\ttraining's l1: 0.0110095\tvalid_1's l1: 0.241238\n",
      "[2800]\ttraining's l1: 0.00930025\tvalid_1's l1: 0.241109\n",
      "[3000]\ttraining's l1: 0.00789794\tvalid_1's l1: 0.241024\n",
      "[3200]\ttraining's l1: 0.00673407\tvalid_1's l1: 0.240963\n",
      "[3400]\ttraining's l1: 0.00578139\tvalid_1's l1: 0.240938\n",
      "[3600]\ttraining's l1: 0.00497562\tvalid_1's l1: 0.240903\n",
      "[3800]\ttraining's l1: 0.00428765\tvalid_1's l1: 0.24088\n",
      "[4000]\ttraining's l1: 0.00369145\tvalid_1's l1: 0.240857\n",
      "[4200]\ttraining's l1: 0.00319794\tvalid_1's l1: 0.240843\n",
      "[4400]\ttraining's l1: 0.00277135\tvalid_1's l1: 0.24082\n",
      "[4600]\ttraining's l1: 0.00241929\tvalid_1's l1: 0.240813\n",
      "[4800]\ttraining's l1: 0.00211287\tvalid_1's l1: 0.240804\n",
      "[5000]\ttraining's l1: 0.00186037\tvalid_1's l1: 0.240792\n",
      "[5200]\ttraining's l1: 0.00163722\tvalid_1's l1: 0.240783\n",
      "[5400]\ttraining's l1: 0.00143901\tvalid_1's l1: 0.24078\n",
      "[5600]\ttraining's l1: 0.00126951\tvalid_1's l1: 0.240777\n",
      "[5800]\ttraining's l1: 0.00112052\tvalid_1's l1: 0.240775\n",
      "[6000]\ttraining's l1: 0.000992838\tvalid_1's l1: 0.240774\n",
      "[6200]\ttraining's l1: 0.000880344\tvalid_1's l1: 0.240773\n",
      "[6400]\ttraining's l1: 0.000780505\tvalid_1's l1: 0.240774\n",
      "Early stopping, best iteration is:\n",
      "[6246]\ttraining's l1: 0.000856666\tvalid_1's l1: 0.240771\n",
      "fold n°5\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\ttraining's l1: 0.181986\tvalid_1's l1: 0.280161\n",
      "[400]\ttraining's l1: 0.124119\tvalid_1's l1: 0.262753\n",
      "[600]\ttraining's l1: 0.0911599\tvalid_1's l1: 0.255112\n",
      "[800]\ttraining's l1: 0.0692742\tvalid_1's l1: 0.250906\n",
      "[1000]\ttraining's l1: 0.0540444\tvalid_1's l1: 0.248414\n",
      "[1200]\ttraining's l1: 0.042828\tvalid_1's l1: 0.246986\n",
      "[1400]\ttraining's l1: 0.0344298\tvalid_1's l1: 0.245821\n",
      "[1600]\ttraining's l1: 0.027938\tvalid_1's l1: 0.245139\n",
      "[1800]\ttraining's l1: 0.0228256\tvalid_1's l1: 0.244636\n",
      "[2000]\ttraining's l1: 0.0188415\tvalid_1's l1: 0.244255\n",
      "[2200]\ttraining's l1: 0.0156575\tvalid_1's l1: 0.244034\n",
      "[2400]\ttraining's l1: 0.013087\tvalid_1's l1: 0.243862\n",
      "[2600]\ttraining's l1: 0.0110024\tvalid_1's l1: 0.243734\n",
      "[2800]\ttraining's l1: 0.00930153\tvalid_1's l1: 0.243621\n",
      "[3000]\ttraining's l1: 0.00790372\tvalid_1's l1: 0.24351\n",
      "[3200]\ttraining's l1: 0.00673609\tvalid_1's l1: 0.243447\n",
      "[3400]\ttraining's l1: 0.00579082\tvalid_1's l1: 0.243411\n",
      "[3600]\ttraining's l1: 0.00498531\tvalid_1's l1: 0.243384\n",
      "[3800]\ttraining's l1: 0.00429926\tvalid_1's l1: 0.243339\n",
      "[4000]\ttraining's l1: 0.0037037\tvalid_1's l1: 0.243302\n",
      "[4200]\ttraining's l1: 0.00321322\tvalid_1's l1: 0.243283\n",
      "[4400]\ttraining's l1: 0.002792\tvalid_1's l1: 0.243268\n",
      "[4600]\ttraining's l1: 0.00243135\tvalid_1's l1: 0.24326\n",
      "[4800]\ttraining's l1: 0.00212711\tvalid_1's l1: 0.243253\n",
      "[5000]\ttraining's l1: 0.00186117\tvalid_1's l1: 0.24324\n",
      "[5200]\ttraining's l1: 0.00163427\tvalid_1's l1: 0.243235\n",
      "[5400]\ttraining's l1: 0.0014341\tvalid_1's l1: 0.243226\n",
      "[5600]\ttraining's l1: 0.00126304\tvalid_1's l1: 0.243219\n",
      "[5800]\ttraining's l1: 0.00111642\tvalid_1's l1: 0.243215\n",
      "[6000]\ttraining's l1: 0.000985444\tvalid_1's l1: 0.243213\n",
      "[6200]\ttraining's l1: 0.00087356\tvalid_1's l1: 0.24321\n",
      "[6400]\ttraining's l1: 0.000776732\tvalid_1's l1: 0.243204\n",
      "[6600]\ttraining's l1: 0.000692417\tvalid_1's l1: 0.243202\n",
      "[6800]\ttraining's l1: 0.000615881\tvalid_1's l1: 0.243199\n",
      "[7000]\ttraining's l1: 0.000548508\tvalid_1's l1: 0.243196\n",
      "[7200]\ttraining's l1: 0.000490878\tvalid_1's l1: 0.243195\n",
      "[7400]\ttraining's l1: 0.000439462\tvalid_1's l1: 0.243195\n",
      "[7600]\ttraining's l1: 0.000393517\tvalid_1's l1: 0.243193\n",
      "[7800]\ttraining's l1: 0.00035358\tvalid_1's l1: 0.243191\n",
      "[8000]\ttraining's l1: 0.000317573\tvalid_1's l1: 0.24319\n",
      "Early stopping, best iteration is:\n",
      "[7934]\ttraining's l1: 0.000329049\tvalid_1's l1: 0.24319\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "with base.timer(\"Light GBM model\"):\n",
    "        mean_log_mae, submit_file = \\\n",
    "        Assistance.split_execute_model(split_value = 'type',\n",
    "                                                         train=train_df, \n",
    "                                                         test=test_df, \n",
    "                                                         model=LightGBM.lightgbm, \n",
    "                                                         model_arg = arg1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lightgbm normal validation Mean log MAE: -0.6860\n"
     ]
    }
   ],
   "source": [
    "# result (Mean Log MAE)\n",
    "print(\"Lightgbm normal validation Mean log MAE: %.4f\" % np.mean(mean_log_mae))\n",
    "# submit\n",
    "Process.submit(submit_file ,tech = \"lightgbm_giba_output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x3600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# importance  (要考察, 上記の関数だと importance持ってきていない)\n",
    "Process.display_importances(lgb_importance,title=\"LightGBM normal importance\",file_name = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
